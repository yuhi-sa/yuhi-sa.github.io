<!DOCTYPE html>
<html lang="ja" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Code description of ROS package to make op3 acquire walking using reinforcement learning | tomato blog</title>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css"
      integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM"
      crossorigin="anonymous" rel="stylesheet">



  <link rel="stylesheet" href="/css/main.min.27c458cc04c39baa2c5494bd8658476214e123dabef2ece2efc840640fe0fc49.css" integrity="sha256-J8RYzATDm6osVJS9hlhHYhThI9q&#43;8uzi78hAZA/g/Ek=" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/syntax.min.aa0332253f313dc48905008b4ab314155e5a13302588d25bcf4949f7c1abdde0.css" integrity="sha256-qgMyJT8xPcSJBQCLSrMUFV5aEzAliNJbz0lJ98Gr3eA=" crossorigin="anonymous">


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css">


<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"></script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>


<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>


<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>


</head>
<body>
  <header>
    
    <nav class="navbar navbar-expand-lg navbar-light bg-light">
      <div class="navbar-brand">tomato blog</div>
      <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarNav">  
        <ul class="navbar-nav ml-auto">
      <li class="nav-item">
        <a ZgotmplZ href="https://yuhi-sa.github.io/" class="nav-link"> Blog </a>
      </li>
      <li class="nav-item">
        <a ZgotmplZ href="https://yuhi-sa.github.io/tags" class="nav-link"> Tags </a>
      </li>
      <li class="nav-item">
        <a ZgotmplZ href="https://yuhi-sa.github.io/posts/about" class="nav-link"> About </a>
      </li>
      <li class="nav-item">
        <a ZgotmplZ href="https://yuhi-sa.github.io/posts/privacy_policy" class="nav-link"> privacy policy </a>
      </li>
        </ul>
      </div>
    </nav>


  
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-LN6QP6VVM3');
  </script>



  
  <script data-ad-client="ca-pub-3940256099942544" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>



  </header>
  <main>
    
  <h1>Code description of ROS package to make op3 acquire walking using reinforcement learning</h1>

  
  
  <time datetime="2021-11-02T10:17:23&#43;09:00">2021年11月2日</time>

  <h1 id="introduction">Introduction</h1>
<p>ROS package for ROBOTIS OP3 to acquire walking using reinforcement learning</p>
<ul>
<li><a href="https://github.com/yuhi-sa/op3_walk">op3_walk</a></li>
</ul>
<h1 id="result-video">Result Video</h1>
<ul>
<li><a href="https://github.com/yuhi-sa/op3_walk/blob/main/docs/op3_controller_demo.mp4">op3_controller_demo</a></li>
</ul>
<h1 id="methods">Methods</h1>
<p>This package uses deep reinforcement learning (DQN).<br>
The action value function is defined as a three-layer neural network (NN), and the Q-value is updated as follows</p>
<p>$Q(s_t,a_t) = Q(s_t,a_t) + \eta(R_{t+1)} + \gamma \max_a Q(s_{t+1},a) - Q(s_t,a_t)$</p>
<p>The neural network is updated by back propagation using the loss function L.</p>
<p>$ L = \mathbb{E}(R_{t+1} + \gamma \max Q(s_{t+1},a_t)- Q(s_t,a_t))$</p>
<h1 id="program">Program</h1>
<h2 id="functionpyhttpsgithubcomyuhi-saop3_walkblobmainscriptsfunctionpy-and-motionpyhttpsgithubcomyuhi-saop3_walkblobmainscriptsmotionpy"><a href="https://github.com/yuhi-sa/op3_walk/blob/main/scripts/function.py">function.py</a> and <a href="https://github.com/yuhi-sa/op3_walk/blob/main/scripts/motion.py">motion.py</a></h2>
<p>[function] contains the definition of the agent.<br>
The Agent class has a Brain class that defines the neural network.<br>
With the actions and states stored in the ReplayMemory class, Brain calculates and updates the loss.<br>
The actions are discretized, and epsilon-greedy selection is made among the actions defined in [motion].</p>
<p>I used the code from this book as a reference.</p>
<ul>
<li><a href="https://github.com/YutaroOgawa/Deep-Reinforcement-Learning-Book">Deep-Reinforcement-Learning-Book</a></li>
</ul>
<h2 id="learningpyhttpsgithubcomyuhi-saop3_walkblobmainscriptslearningpy"><a href="https://github.com/yuhi-sa/op3_walk/blob/main/scripts/learning.py">learning.py</a></h2>
<p>Input the state subscribed from [controller] to the Agent, calculate the action, and publish it.  <br>
This one uses pytorch to define the neural network, so it needs to be run in python3.</p>
<h2 id="controllerpyhttpsgithubcomyuhi-saop3_walkblobmainscriptscontrollerpy"><a href="https://github.com/yuhi-sa/op3_walk/blob/main/scripts/controller.py">controller.py</a></h2>
<p>[controller]. It subscribes to actions published by [learning] and actually runs op3.
Then publish the state. <br>
Due to the op3 package, you will need to run this in python2.</p>
<h1 id="learning-curve">Learning curve</h1>
<p>Learning curve for walking distance</p>
<p><img src="https://github.com/yuhi-sa/op3_walk/blob/main/docs/learning.png?raw=true" alt="歩行距離"></p>
  
  <div>
    <div>Tags:</div>
    <ul>
        <li><a href="/tags/others/">others</a></li>
    </ul>
  </div>


  </main>
  <footer>
    <p>Copyright 2023. All rights reserved.</p>

  </footer>
</body>
</html>
