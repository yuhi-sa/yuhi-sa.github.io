<!doctype html><html lang=ja dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><meta name=robots content="index,follow"><meta property="og:title" content="強化学習を用いてop3に歩行獲得させるROSパッケージのコード説明 | tomato blog"><meta property="og:description" content="勉強したことなどをメモしています"><meta property="og:image" content="https://yuhi-sa.github.io/ogp.jpeg"><meta property="og:url" content="https://yuhi-sa.github.io/posts/20211102_op3/1/"><meta name=twitter:card content="summary_large_image"><title>強化学習を用いてop3に歩行獲得させるROSパッケージのコード説明 | tomato blog</title><link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css rel=stylesheet><link rel=stylesheet href=/css/main.min.cbcf0adf3096d54322591302ca01248346902aa2474afcbd71c3a1b999e09ad9.css integrity="sha256-y88K3zCW1UMiWRMCygEkg0aQKqJHSvy9ccOhuZngmtk=" crossorigin=anonymous><link rel=stylesheet href=/css/syntax.min.aa0332253f313dc48905008b4ab314155e5a13302588d25bcf4949f7c1abdde0.css integrity="sha256-qgMyJT8xPcSJBQCLSrMUFV5aEzAliNJbz0lJ98Gr3eA=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js></script><script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script></head><body><header><nav class="navbar navbar-expand-lg navbar-light bg-light"><div class=navbar-brand style=padding-left:10px>tomato blog</div><button class="navbar-toggler ml-auto" type=button data-bs-toggle=collapse data-bs-target=#navbarNav aria-controls=navbarNav aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarNav><ul class="navbar-nav ml-auto"><li class=nav-item><a zgotmplz href=https://yuhi-sa.github.io/ class=nav-link>Blog</a></li><li class=nav-item><a zgotmplz href=https://yuhi-sa.github.io/tags class=nav-link>Tags</a></li><li class=nav-item><a zgotmplz href=https://yuhi-sa.github.io/posts/about class=nav-link>About</a></li><li class=nav-item><a zgotmplz href=https://yuhi-sa.github.io/posts/privacy_policy class=nav-link>Privacy policy</a></li></ul></div></nav><script async src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-LN6QP6VVM3")</script><script data-ad-client=ca-pub-9558545098866170 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></header><main><div style="max-width:80%;margin:0 auto"><h1 id=強化学習を用いてop3に歩行獲得させるrosパッケージのコード説明>強化学習を用いてop3に歩行獲得させるROSパッケージのコード説明</h1><h2 id=はじめに>はじめに</h2><p>ROBOTIS OP3にGazeboシミュレーション内で強化学習を用いて歩行獲得させるROSパッケージのコード説明の記事です．</p><ul><li><a href=https://github.com/yuhi-sa/op3_walk>op3_walk</a></li></ul><h2 id=結果の動画>結果の動画</h2><ul><li><a href=https://github.com/yuhi-sa/op3_walk/blob/main/docs/op3_controller_demo.mp4>op3_controller_demo</a></li></ul><h2 id=手法の説明>手法の説明</h2><p>深層強化学習(DQN)を使用しています．<br>行動価値関数は，3層のニューラルネットワーク(NN)として定義しQ値を以下のように更新し，</p><p>$Q(s_t,a_t) = Q(s_t,a_t) + \eta(R_{t+1)} + \gamma \max_a Q(s_{t+1},a) - Q(s_t,a_t)$</p><p>損失関数$L$を用いて誤差逆伝播しニューラルネットを更新しています．</p><p>$ L = \mathbb{E}(R_{t+1} + \gamma \max Q(s_{t+1},a_t)- Q(s_t,a_t))$</p><h2 id=プログラムの説明>プログラムの説明</h2><h3 id=functionpy-and-motionpy><a href=https://github.com/yuhi-sa/op3_walk/blob/main/scripts/function.py>function.py</a> and <a href=https://github.com/yuhi-sa/op3_walk/blob/main/scripts/motion.py>motion.py</a></h3><p>[function]にはエージェントの定義を書いています．<br>Agentクラスが，ニューラルネットの定義をしているBrainクラスを持っています．ReplayMemoryクラスに蓄積される行動と状態で，Brainは損失の計算と更新を行います．行動は離散化しており，[motion]で定義されている行動の中から，epsilon-greedy選択を行います．<br>こちらの書籍のコードを参考にしています．</p><ul><li><a href=https://github.com/YutaroOgawa/Deep-Reinforcement-Learning-Book>Deep-Reinforcement-Learning-Book</a></li></ul><h3 id=learningpy><a href=https://github.com/yuhi-sa/op3_walk/blob/main/scripts/learning.py>learning.py</a></h3><p>[learning]では，[function]で定義したAgentクラスを継承します．Agentに，[controller]からsubscribeした状態を入力，行動を計算し，publishします．こちらはニューラルネットワークの定義にpytorchを使っているため，python3系で実行する必要があります．</p><h3 id=controllerpy><a href=https://github.com/yuhi-sa/op3_walk/blob/main/scripts/controller.py>controller.py</a></h3><p>[controller]は．[learning]からpublishされた行動をsubscribeして，実際にop3を動かします．そして，状態をpublishします．こちらはop3のパッケージの関係で，python2系で実行する必要があります．</p><h2 id=学習曲線>学習曲線</h2><p>歩行距離の学習曲線
<img style="max-width:50%;height:auto;display:block;margin:0 auto" src="https://github.com/yuhi-sa/op3_walk/blob/main/docs/learning.png?raw=true" alt=歩行距離></p></div><div><div>Tags:</div><ul><li><a href=/tags/%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92/>強化学習</a></li></ul></div><nav aria-label=breadcrumb><ol class=breadcrumb><li class=breadcrumb-item><a href=/>Home</a></li><li class="breadcrumb-item active" aria-current=page>強化学習を用いてop3に歩行獲得させるROSパッケージのコード説明</li></ol></nav></main><footer><p style=text-align:center>Copyright 2025. All rights reserved.</p></footer><link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css rel=stylesheet><link rel=stylesheet href=/css/main.min.cbcf0adf3096d54322591302ca01248346902aa2474afcbd71c3a1b999e09ad9.css integrity="sha256-y88K3zCW1UMiWRMCygEkg0aQKqJHSvy9ccOhuZngmtk=" crossorigin=anonymous><link rel=stylesheet href=/css/syntax.min.aa0332253f313dc48905008b4ab314155e5a13302588d25bcf4949f7c1abdde0.css integrity="sha256-qgMyJT8xPcSJBQCLSrMUFV5aEzAliNJbz0lJ98Gr3eA=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js></script><script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script></body></html>