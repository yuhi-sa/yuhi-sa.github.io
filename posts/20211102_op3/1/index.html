<!DOCTYPE html>
<html lang="ja" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>強化学習を用いてop3に歩行獲得させるROSパッケージのコード説明 | tomato blog</title>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css"
      integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM"
      crossorigin="anonymous" rel="stylesheet">



  <link rel="stylesheet" href="/css/main.min.27c458cc04c39baa2c5494bd8658476214e123dabef2ece2efc840640fe0fc49.css" integrity="sha256-J8RYzATDm6osVJS9hlhHYhThI9q&#43;8uzi78hAZA/g/Ek=" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/syntax.min.aa0332253f313dc48905008b4ab314155e5a13302588d25bcf4949f7c1abdde0.css" integrity="sha256-qgMyJT8xPcSJBQCLSrMUFV5aEzAliNJbz0lJ98Gr3eA=" crossorigin="anonymous">


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css">


<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"></script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>


<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>


<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>


</head>
<body>
  <header>
    
    <nav class="navbar navbar-expand-lg navbar-light bg-light">
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarNav">
        
        <div class="navbar-brand">tomato blog</div>
        
        <ul class="navbar-nav ml-auto">
      <li class="nav-item">
        <a ZgotmplZ href="https://yuhi-sa.github.io/" class="nav-link"> Blog </a>
      </li>
      <li class="nav-item">
        <a ZgotmplZ href="https://yuhi-sa.github.io/tags" class="nav-link"> Tags </a>
      </li>
      <li class="nav-item">
        <a ZgotmplZ href="https://yuhi-sa.github.io/posts/about" class="nav-link"> About </a>
      </li>
      <li class="nav-item">
        <a ZgotmplZ href="https://yuhi-sa.github.io/posts/privacy_policy" class="nav-link"> privacy policy </a>
      </li>
        </ul>
      </div>
    </nav>


  
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-LN6QP6VVM3');
  </script>


<script data-ad-client="ca-pub-3940256099942544" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


  </header>
  <main>
    
  <h1>強化学習を用いてop3に歩行獲得させるROSパッケージのコード説明</h1>

  
  
  <time datetime="2021-11-02T10:17:23&#43;09:00">2021年11月2日</time>

  <h1 id="はじめに">はじめに</h1>
<p>ROBOTIS OP3にGazeboシミュレーション内で強化学習を用いて歩行獲得させるROSパッケージのコード説明の記事です．</p>
<ul>
<li><a href="https://github.com/yuhi-sa/op3_walk">op3_walk</a></li>
</ul>
<h1 id="結果の動画">結果の動画</h1>
<ul>
<li><a href="https://github.com/yuhi-sa/op3_walk/blob/main/docs/op3_controller_demo.mp4">op3_controller_demo</a></li>
</ul>
<h1 id="手法の説明">手法の説明</h1>
<p>深層強化学習(DQN)を使用しています．<br>
行動価値関数は，3層のニューラルネットワーク(NN)として定義しQ値を以下のように更新し，</p>
<p>$Q(s_t,a_t) = Q(s_t,a_t) + \eta(R_{t+1)} + \gamma \max_a Q(s_{t+1},a) - Q(s_t,a_t)$</p>
<p>損失関数$L$を用いて誤差逆伝播しニューラルネットを更新しています．</p>
<p>$ L = \mathbb{E}(R_{t+1} + \gamma \max Q(s_{t+1},a_t)- Q(s_t,a_t))$</p>
<h1 id="プログラムの説明">プログラムの説明</h1>
<h2 id="functionpyhttpsgithubcomyuhi-saop3_walkblobmainscriptsfunctionpy-and-motionpyhttpsgithubcomyuhi-saop3_walkblobmainscriptsmotionpy"><a href="https://github.com/yuhi-sa/op3_walk/blob/main/scripts/function.py">function.py</a> and <a href="https://github.com/yuhi-sa/op3_walk/blob/main/scripts/motion.py">motion.py</a></h2>
<p>[function]にはエージェントの定義を書いています．<br>
Agentクラスが，ニューラルネットの定義をしているBrainクラスを持っています．ReplayMemoryクラスに蓄積される行動と状態で，Brainは損失の計算と更新を行います．行動は離散化しており，[motion]で定義されている行動の中から，epsilon-greedy選択を行います．<br>
こちらの書籍のコードを参考にしています．</p>
<ul>
<li><a href="https://github.com/YutaroOgawa/Deep-Reinforcement-Learning-Book">Deep-Reinforcement-Learning-Book</a></li>
</ul>
<h2 id="learningpyhttpsgithubcomyuhi-saop3_walkblobmainscriptslearningpy"><a href="https://github.com/yuhi-sa/op3_walk/blob/main/scripts/learning.py">learning.py</a></h2>
<p>[learning]では，[function]で定義したAgentクラスを継承します．Agentに，[controller]からsubscribeした状態を入力，行動を計算し，publishします．こちらはニューラルネットワークの定義にpytorchを使っているため，python3系で実行する必要があります．</p>
<h2 id="controllerpyhttpsgithubcomyuhi-saop3_walkblobmainscriptscontrollerpy"><a href="https://github.com/yuhi-sa/op3_walk/blob/main/scripts/controller.py">controller.py</a></h2>
<p>[controller]は．[learning]からpublishされた行動をsubscribeして，実際にop3を動かします．そして，状態をpublishします．こちらはop3のパッケージの関係で，python2系で実行する必要があります．</p>
<h1 id="学習曲線">学習曲線</h1>
<p>歩行距離の学習曲線
<img src="https://github.com/yuhi-sa/op3_walk/blob/main/docs/learning.png?raw=true" alt="歩行距離"></p>
  
  <div>
    <div>Tags:</div>
    <ul>
        <li><a href="/tags/%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92/">強化学習</a></li>
    </ul>
  </div>


  </main>
  <footer>
    <p>Copyright 2023. All rights reserved.</p>

  </footer>
</body>
</html>
