<!doctype html><html lang=ja dir=ltr data-theme=light><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#e74c3c"><meta name=format-detection content="telephone=no"><meta name=robots content="index,follow"><meta name=description content="ベイズ最適化のアルゴリズムをPythonで実装します。ガウス過程回帰の基礎から獲得関数（EI, UCB, PI）の数式、1D関数での最適化デモまで解説します。"><meta name=keywords content="機械学習,最適化,ベイズ統計,Python"><meta name=author content="yuhi-sa"><link rel=canonical href=https://yuhi-sa.github.io/posts/20260223_bayesian_optimization/1/><meta property="og:type" content="article"><meta property="og:title" content="ベイズ最適化の基礎とPython実装"><meta property="og:description" content="ベイズ最適化のアルゴリズムをPythonで実装します。ガウス過程回帰の基礎から獲得関数（EI, UCB, PI）の数式、1D関数での最適化デモまで解説します。"><meta property="og:url" content="https://yuhi-sa.github.io/posts/20260223_bayesian_optimization/1/"><meta property="og:site_name" content="tomato blog"><meta property="og:locale" content="ja"><meta property="og:image" content="https://yuhi-sa.github.io/ogp.jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="article:published_time" content="2026-02-23T10:00:00+09:00"><meta property="article:modified_time" content="2026-02-23T16:03:15+09:00"><meta property="article:tag" content="機械学習"><meta property="article:tag" content="最適化"><meta property="article:tag" content="ベイズ統計"><meta property="article:tag" content="Python"><meta property="article:section" content="posts"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="ベイズ最適化の基礎とPython実装"><meta name=twitter:description content="ベイズ最適化のアルゴリズムをPythonで実装します。ガウス過程回帰の基礎から獲得関数（EI, UCB, PI）の数式、1D関数での最適化デモまで解説します。"><meta name=twitter:image content="https://yuhi-sa.github.io/ogp.jpeg"><title>ベイズ最適化の基礎とPython実装 | tomato blog</title><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><link rel=preconnect href=https://pagead2.googlesyndication.com crossorigin><link rel=dns-prefetch href=https://pagead2.googlesyndication.com><link rel=icon href=https://yuhi-sa.github.io/favicon.ico><link rel=alternate hreflang=en href=https://yuhi-sa.github.io/en/posts/20260223_bayesian_optimization/1/><link rel=alternate hreflang=ja href=https://yuhi-sa.github.io/posts/20260223_bayesian_optimization/1/><link rel=alternate hreflang=x-default href=https://yuhi-sa.github.io/posts/20260223_bayesian_optimization/1/><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ベイズ最適化の基礎とPython実装","description":"ベイズ最適化のアルゴリズムをPythonで実装します。ガウス過程回帰の基礎から獲得関数（EI, UCB, PI）の数式、1D関数での最適化デモまで解説します。","author":{"@type":"Person","name":"yuhi-sa","url":"https:\/\/yuhi-sa.github.io\/"},"publisher":{"@type":"Organization","name":"tomato blog","logo":{"@type":"ImageObject","url":"https:\/\/yuhi-sa.github.io\/ogp.jpeg"},"url":"https:\/\/yuhi-sa.github.io\/"},"datePublished":"2026-02-23T10:00:00\u002b09:00","dateModified":"2026-02-23T16:03:15\u002b09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/yuhi-sa.github.io\/posts\/20260223_bayesian_optimization\/1\/"},"url":"https:\/\/yuhi-sa.github.io\/posts\/20260223_bayesian_optimization\/1\/","wordCount":781,"keywords":["機械学習","最適化","ベイズ統計","Python"],"articleSection":"Posts","inLanguage":"ja","timeRequired":"PT4M"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"tomato blog","item":"https:\/\/yuhi-sa.github.io\/"},{"@type":"ListItem","position":2,"name":"Posts","item":"https:\/\/yuhi-sa.github.io\/posts\/"},{"@type":"ListItem","position":3,"name":"ベイズ最適化の基礎とPython実装"}]}</script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw==" crossorigin=anonymous referrerpolicy=no-referrer><link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH crossorigin=anonymous><link rel=stylesheet href=/css/variables.min.72a177faa7b12de55dcc39c4ab6b6392116718d5e2735dab0214511354ecb973.css integrity="sha256-cqF3+qexLeVdzDnEq2tjkhFnGNXic12rAhRRE1TsuXM=" crossorigin=anonymous><link rel=stylesheet href=/css/main.min.403a82b29e94ee6e7a39204b5082cdf8b4966cfb44115390da7d8867a5006acd.css integrity="sha256-QDqCsp6U7m56OSBLUILN+LSWbPtEEVOQ2n2IZ6UAas0=" crossorigin=anonymous><link rel=stylesheet href=/css/syntax.min.e379066489e20d5433ca35ac1f468fd9e8859705a62d77a79bb7379ac3613848.css integrity="sha256-43kGZIniDVQzyjWsH0aP2eiFlwWmLXenm7c3msNhOEg=" crossorigin=anonymous><style>body{font-family:-apple-system,BlinkMacSystemFont,inter,segoe ui,Roboto,sans-serif;line-height:1.5;color:#000;background:#fff}[data-theme=dark] body{color:#fff;background:#000}.container{max-width:768px;margin:0 auto;padding:0 1rem}</style><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js integrity=sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz crossorigin=anonymous defer></script><script src=/js/dark-mode.min.3e457dc8346f064bee795e6f9b73e1516dcd059e750c521fe4b445f9ea9a7821.js integrity="sha256-PkV9yDRvBkvueV5vm3PhUW3NBZ51DFIf5LRF+eqaeCE=" defer></script><script>window.addEventListener("load",function(){const e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3",document.head.appendChild(e),e.onload=function(){window.dataLayer=window.dataLayer||[];function e(){dataLayer.push(arguments)}e("js",new Date),e("config","G-LN6QP6VVM3")}})</script><script>window.MathJax={tex:{inlineMath:[["\\(","\\)"]],displayMath:[["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js id=mathjax-script async></script></head><body itemscope itemtype=https://schema.org/WebPage class=theme-tomatohugo><a href=#main-content class="skip-link sr-only sr-only-focusable" aria-label="Skip to main content">Skip to main content</a><header role=banner class=site-header><nav class="navbar navbar-expand-lg navbar-light bg-light" role=navigation aria-label="Main navigation"><div class=container><a class=navbar-brand href=https://yuhi-sa.github.io/ aria-label="Return to tomato blog homepage">tomato blog
</a><button class="navbar-toggler d-lg-none" type=button data-bs-toggle=collapse data-bs-target=#navbarNav aria-controls=navbarNav aria-expanded=false aria-label="Toggle navigation menu">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarNav><ul class="navbar-nav ms-auto" role=menubar><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/ role=menuitem aria-label="Navigate to Blog">Blog</a></li><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/tags/ role=menuitem aria-label="Navigate to Tags">Tags</a></li><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/posts/about/ role=menuitem aria-label="Navigate to About">About</a></li><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/posts/privacy_policy/ role=menuitem aria-label="Navigate to Privacy policy">Privacy policy</a></li><li class=nav-item role=none><button id=darkModeToggle class="nav-link btn btn-link border-0" type=button role=menuitem aria-label="Toggle dark mode" title="Switch between light and dark themes">
<i class="fas fa-moon" id=darkModeIcon aria-hidden=true></i>
<span class="d-lg-none ms-2">ダークモード</span></button></li></ul></div></div></nav><script data-ad-client=ca-pub-9558545098866170 async crossorigin=anonymous src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></header><main id=main-content role=main class=site-main aria-label="Main content"><div class="container mt-4"><div class="row justify-content-center"><div class=col-lg-8><article itemscope itemtype=https://schema.org/Article><header class=article-header><h1 itemprop=headline>ベイズ最適化の基礎とPython実装</h1><p class="lead article-description" itemprop=description>ベイズ最適化のアルゴリズムをPythonで実装します。ガウス過程回帰の基礎から獲得関数（EI, UCB, PI）の数式、1D関数での最適化デモまで解説します。</p><div class=article-meta><time datetime=2026-02-23T10:00:00+09:00 itemprop=datePublished><i class="far fa-calendar-alt me-1" aria-hidden=true></i>
February 23, 2026
</time><time datetime=2026-02-23T16:03:15+09:00 itemprop=dateModified class=ms-3><i class="far fa-edit me-1" aria-hidden=true></i>
Updated
February 23, 2026
</time><span aria-label="Reading time" class=ms-3><i class="far fa-clock me-1" aria-hidden=true></i>
4 min read</span></div><div class=article-tags role=group aria-label="Article tags"><a href=/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/ class="badge badge-custom text-decoration-none me-1" rel=tag itemprop=keywords>機械学習
</a><a href=/tags/%E6%9C%80%E9%81%A9%E5%8C%96/ class="badge badge-custom text-decoration-none me-1" rel=tag itemprop=keywords>最適化
</a><a href=/tags/%E3%83%99%E3%82%A4%E3%82%BA%E7%B5%B1%E8%A8%88/ class="badge badge-custom text-decoration-none me-1" rel=tag itemprop=keywords>ベイズ統計
</a><a href=/tags/python/ class="badge badge-custom text-decoration-none me-1" rel=tag itemprop=keywords>Python</a></div></header><div class=article-content itemprop=articleBody><h2 id=ベイズ最適化とは>ベイズ最適化とは</h2><p>ベイズ最適化（Bayesian Optimization）は、<strong>評価コストの高いブラックボックス関数</strong>の大域的最適化のための手法です。以下のような問題に適しています：</p>\[
\mathbf{x}^* = \arg\min_{\mathbf{x} \in \mathcal{X}} f(\mathbf{x}) \tag{1}
\]<p>ここで \(f\) は解析的な勾配が得られず、1回の評価に大きなコスト（時間・費用）がかかる関数です。典型的な応用例として、機械学習モデルのハイパーパラメータ最適化、実験計画、材料探索などがあります。</p><p>ベイズ最適化は以下の2つの要素で構成されます：</p><ol><li><strong>代理モデル（Surrogate Model）</strong>: 目的関数を近似する確率モデル（通常はガウス過程）</li><li><strong>獲得関数（Acquisition Function）</strong>: 次に評価すべき点を決定する関数</li></ol><p>少数の観測データから代理モデルを構築し、獲得関数を最大化する点を逐次的に選択することで、効率的に最適解を探索します。</p><h2 id=ガウス過程回帰>ガウス過程回帰</h2><h3 id=カーネル関数>カーネル関数</h3><p>ガウス過程（Gaussian Process, GP）は、関数の事前分布を定義する確率モデルです。GPは平均関数 \(m(\mathbf{x})\) とカーネル関数 \(k(\mathbf{x}, \mathbf{x}')\) で特徴付けられます：</p>\[
f(\mathbf{x}) \sim \mathcal{GP}(m(\mathbf{x}), k(\mathbf{x}, \mathbf{x}')) \tag{2}
\]<p>最も広く使われるカーネルはRBF（Radial Basis Function）カーネル（二乗指数カーネルとも呼ばれる）です：</p>\[
k(\mathbf{x}, \mathbf{x}') = \sigma_f^2 \exp\left(-\frac{\|\mathbf{x} - \mathbf{x}'\|^2}{2l^2}\right) \tag{3}
\]<p>ここで \(\sigma_f^2\) は出力の分散、\(l\) は長さスケールパラメータです。\(l\) が大きいほど関数は滑らかになります。</p><h3 id=事後分布>事後分布</h3><p>\(n\) 個の観測データ \(\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^n\) が与えられたとき、新しい入力 \(\mathbf{x}_*\) での予測分布は以下のようになります。観測ノイズ \(\sigma_n^2\) を仮定すると：</p>\[
\mu(\mathbf{x}_*) = \mathbf{k}_*^T (\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{y} \tag{4}
\]\[
\sigma^2(\mathbf{x}_*) = k(\mathbf{x}_*, \mathbf{x}_*) - \mathbf{k}_*^T (\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{k}_* \tag{5}
\]<p>ここで：</p><ul><li>\(\mathbf{K}\) は \(n \times n\) のカーネル行列で \(K_{ij} = k(\mathbf{x}_i, \mathbf{x}_j)\)</li><li>\(\mathbf{k}_* = [k(\mathbf{x}_1, \mathbf{x}_*), \ldots, k(\mathbf{x}_n, \mathbf{x}_*)]^T\)</li><li>\(\mathbf{y} = [y_1, \ldots, y_n]^T\)</li></ul><p>式(4)は予測平均、式(5)は予測の不確実性を表します。データが密な領域では \(\sigma^2\) が小さくなり、データが少ない領域では大きくなります。</p><h2 id=獲得関数>獲得関数</h2><p>獲得関数は「次にどこを評価すべきか」を決定します。予測平均（活用）と予測分散（探索）のバランスをとることが重要です。</p><h3 id=expected-improvementei>Expected Improvement（EI）</h3><p>現在の最良値 \(f(\mathbf{x}^+)\) からの改善量の期待値を最大化します：</p>\[
\text{EI}(\mathbf{x}) = \mathbb{E}[\max(f(\mathbf{x}^+) - f(\mathbf{x}), 0)] \tag{6}
\]<p>ガウス過程の予測分布を用いると、EIは解析的に計算できます：</p>\[
\text{EI}(\mathbf{x}) = (\mu(\mathbf{x}^+) - \mu(\mathbf{x}) - \xi) \Phi(Z) + \sigma(\mathbf{x}) \phi(Z) \tag{7}
\]\[
Z = \frac{\mu(\mathbf{x}^+) - \mu(\mathbf{x}) - \xi}{\sigma(\mathbf{x})} \tag{8}
\]<p>ここで \(\Phi\) と \(\phi\) はそれぞれ標準正規分布の累積分布関数と確率密度関数、\(\xi \geq 0\) は探索を促進するパラメータです。最小化問題の場合、\(f(\mathbf{x}^+)\) は現在の最小観測値です。</p><h3 id=upper-confidence-bounducb>Upper Confidence Bound（UCB）</h3><p>予測平均から予測標準偏差のスケーリングを引いたものを最小化します（最小化問題の場合はLower Confidence Bound）：</p>\[
\text{UCB}(\mathbf{x}) = \mu(\mathbf{x}) - \kappa \sigma(\mathbf{x}) \tag{9}
\]<p>\(\kappa > 0\) は探索と活用のトレードオフを制御します。\(\kappa\) が大きいほど探索的になります。</p><h3 id=probability-of-improvementpi>Probability of Improvement（PI）</h3><p>現在の最良値を改善する確率を最大化します：</p>\[
\text{PI}(\mathbf{x}) = \Phi\left(\frac{\mu(\mathbf{x}^+) - \mu(\mathbf{x}) - \xi}{\sigma(\mathbf{x})}\right) \tag{10}
\]<p>PIは計算が簡単ですが、改善量の大きさを考慮しないため、局所解に収束しやすい欠点があります。</p><p>以下の図は、同じGPサロゲートモデルに対して3つの獲得関数がどのように異なる探索戦略を示すかを比較したものです。</p><p><img src=/posts/20260223_bayesian_optimization/acquisition_functions_comparison.png alt="獲得関数の比較（EI, UCB, PI）"></p><h2 id=python実装>Python実装</h2><h3 id=ガウス過程クラス>ガウス過程クラス</h3><p>NumPyとSciPyを用いてガウス過程回帰をスクラッチで実装します。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>norm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>GaussianProcess</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>length_scale</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>signal_var</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>noise_var</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>l</span> <span class=o>=</span> <span class=n>length_scale</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>sf2</span> <span class=o>=</span> <span class=n>signal_var</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>sn2</span> <span class=o>=</span> <span class=n>noise_var</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>X_train</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>y_train</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>K_inv</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>kernel</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X1</span><span class=p>,</span> <span class=n>X2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;RBFカーネル（式3）&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>dist_sq</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>X1</span><span class=o>**</span><span class=mi>2</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdims</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> \
</span></span><span class=line><span class=cl>                  <span class=o>-</span> <span class=mf>2.0</span> <span class=o>*</span> <span class=n>X1</span> <span class=o>@</span> <span class=n>X2</span><span class=o>.</span><span class=n>T</span> \
</span></span><span class=line><span class=cl>                  <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>X2</span><span class=o>**</span><span class=mi>2</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>sf2</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=mf>0.5</span> <span class=o>*</span> <span class=n>dist_sq</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>l</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;観測データでGPを学習&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>X_train</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>y_train</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>K</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>kernel</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>X</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>sn2</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>X</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>K_inv</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>inv</span><span class=p>(</span><span class=n>K</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X_new</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;新しい点での予測平均と予測分散（式4, 5）&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>k_star</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>kernel</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>X_train</span><span class=p>,</span> <span class=n>X_new</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>mu</span> <span class=o>=</span> <span class=n>k_star</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=bp>self</span><span class=o>.</span><span class=n>K_inv</span> <span class=o>@</span> <span class=bp>self</span><span class=o>.</span><span class=n>y_train</span>
</span></span><span class=line><span class=cl>        <span class=n>var</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>sf2</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>diag</span><span class=p>(</span><span class=n>k_star</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=bp>self</span><span class=o>.</span><span class=n>K_inv</span> <span class=o>@</span> <span class=n>k_star</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>var</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>maximum</span><span class=p>(</span><span class=n>var</span><span class=p>,</span> <span class=mf>1e-10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>mu</span><span class=p>,</span> <span class=n>var</span>
</span></span></code></pre></div><h3 id=獲得関数の実装>獲得関数の実装</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>expected_improvement</span><span class=p>(</span><span class=n>mu</span><span class=p>,</span> <span class=n>var</span><span class=p>,</span> <span class=n>y_best</span><span class=p>,</span> <span class=n>xi</span><span class=o>=</span><span class=mf>0.01</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Expected Improvement（式7, 8）&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>sigma</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>var</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>np</span><span class=o>.</span><span class=n>errstate</span><span class=p>(</span><span class=n>divide</span><span class=o>=</span><span class=s2>&#34;ignore&#34;</span><span class=p>,</span> <span class=n>invalid</span><span class=o>=</span><span class=s2>&#34;ignore&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>Z</span> <span class=o>=</span> <span class=p>(</span><span class=n>y_best</span> <span class=o>-</span> <span class=n>mu</span> <span class=o>-</span> <span class=n>xi</span><span class=p>)</span> <span class=o>/</span> <span class=n>sigma</span>
</span></span><span class=line><span class=cl>        <span class=n>ei</span> <span class=o>=</span> <span class=p>(</span><span class=n>y_best</span> <span class=o>-</span> <span class=n>mu</span> <span class=o>-</span> <span class=n>xi</span><span class=p>)</span> <span class=o>*</span> <span class=n>norm</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>Z</span><span class=p>)</span> <span class=o>+</span> <span class=n>sigma</span> <span class=o>*</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>Z</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ei</span><span class=p>[</span><span class=n>sigma</span> <span class=o>&lt;</span> <span class=mf>1e-10</span><span class=p>]</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>ei</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>upper_confidence_bound</span><span class=p>(</span><span class=n>mu</span><span class=p>,</span> <span class=n>var</span><span class=p>,</span> <span class=n>kappa</span><span class=o>=</span><span class=mf>2.0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;UCB（最小化用：LCB）（式9）&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>sigma</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>var</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>mu</span> <span class=o>-</span> <span class=n>kappa</span> <span class=o>*</span> <span class=n>sigma</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>probability_of_improvement</span><span class=p>(</span><span class=n>mu</span><span class=p>,</span> <span class=n>var</span><span class=p>,</span> <span class=n>y_best</span><span class=p>,</span> <span class=n>xi</span><span class=o>=</span><span class=mf>0.01</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Probability of Improvement（式10）&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>sigma</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>var</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>np</span><span class=o>.</span><span class=n>errstate</span><span class=p>(</span><span class=n>divide</span><span class=o>=</span><span class=s2>&#34;ignore&#34;</span><span class=p>,</span> <span class=n>invalid</span><span class=o>=</span><span class=s2>&#34;ignore&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>Z</span> <span class=o>=</span> <span class=p>(</span><span class=n>y_best</span> <span class=o>-</span> <span class=n>mu</span> <span class=o>-</span> <span class=n>xi</span><span class=p>)</span> <span class=o>/</span> <span class=n>sigma</span>
</span></span><span class=line><span class=cl>        <span class=n>pi</span> <span class=o>=</span> <span class=n>norm</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>Z</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>pi</span><span class=p>[</span><span class=n>sigma</span> <span class=o>&lt;</span> <span class=mf>1e-10</span><span class=p>]</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>pi</span>
</span></span></code></pre></div><h3 id=ベイズ最適化ループ>ベイズ最適化ループ</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>bayesian_optimization</span><span class=p>(</span><span class=n>f</span><span class=p>,</span> <span class=n>bounds</span><span class=p>,</span> <span class=n>n_init</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>n_iter</span><span class=o>=</span><span class=mi>15</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>acq_func</span><span class=o>=</span><span class=s2>&#34;ei&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;ベイズ最適化のメインループ&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 初期点のランダムサンプリング</span>
</span></span><span class=line><span class=cl>    <span class=n>X_init</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=n>bounds</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>bounds</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                               <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>n_init</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>y_init</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>f</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>X_init</span><span class=p>])</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>gp</span> <span class=o>=</span> <span class=n>GaussianProcess</span><span class=p>(</span><span class=n>length_scale</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>signal_var</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                         <span class=n>noise_var</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_sample</span> <span class=o>=</span> <span class=n>X_init</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>y_sample</span> <span class=o>=</span> <span class=n>y_init</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 最適化ループ</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_iter</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>gp</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_sample</span><span class=p>,</span> <span class=n>y_sample</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 候補点での獲得関数の評価</span>
</span></span><span class=line><span class=cl>        <span class=n>X_cand</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>bounds</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>bounds</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=mi>500</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>mu</span><span class=p>,</span> <span class=n>var</span> <span class=o>=</span> <span class=n>gp</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_cand</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y_best</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=n>y_sample</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>acq_func</span> <span class=o>==</span> <span class=s2>&#34;ei&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>acq</span> <span class=o>=</span> <span class=n>expected_improvement</span><span class=p>(</span><span class=n>mu</span><span class=p>,</span> <span class=n>var</span><span class=p>,</span> <span class=n>y_best</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>x_next</span> <span class=o>=</span> <span class=n>X_cand</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>acq</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>acq_func</span> <span class=o>==</span> <span class=s2>&#34;ucb&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>acq</span> <span class=o>=</span> <span class=n>upper_confidence_bound</span><span class=p>(</span><span class=n>mu</span><span class=p>,</span> <span class=n>var</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>x_next</span> <span class=o>=</span> <span class=n>X_cand</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>argmin</span><span class=p>(</span><span class=n>acq</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>acq_func</span> <span class=o>==</span> <span class=s2>&#34;pi&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>acq</span> <span class=o>=</span> <span class=n>probability_of_improvement</span><span class=p>(</span><span class=n>mu</span><span class=p>,</span> <span class=n>var</span><span class=p>,</span> <span class=n>y_best</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>x_next</span> <span class=o>=</span> <span class=n>X_cand</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>acq</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 新しい点を評価して追加</span>
</span></span><span class=line><span class=cl>        <span class=n>y_next</span> <span class=o>=</span> <span class=n>f</span><span class=p>(</span><span class=n>x_next</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>X_sample</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>vstack</span><span class=p>([</span><span class=n>X_sample</span><span class=p>,</span> <span class=n>x_next</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>        <span class=n>y_sample</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>y_sample</span><span class=p>,</span> <span class=n>y_next</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>X_sample</span><span class=p>,</span> <span class=n>y_sample</span><span class=p>,</span> <span class=n>gp</span>
</span></span></code></pre></div><h2 id=1d最適化デモ>1D最適化デモ</h2><p>テスト関数としてノイズのない非凸関数を使い、ベイズ最適化の挙動を確認します。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_function</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;複数の極小値を持つテスト関数&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=mi>3</span> <span class=o>*</span> <span class=n>x</span><span class=p>)</span> <span class=o>+</span> <span class=n>x</span><span class=o>**</span><span class=mi>2</span> <span class=o>*</span> <span class=mf>0.1</span> <span class=o>-</span> <span class=mf>0.5</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=mi>7</span> <span class=o>*</span> <span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>bounds</span> <span class=o>=</span> <span class=p>(</span><span class=o>-</span><span class=mf>3.0</span><span class=p>,</span> <span class=mf>3.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>X_sample</span><span class=p>,</span> <span class=n>y_sample</span><span class=p>,</span> <span class=n>gp</span> <span class=o>=</span> <span class=n>bayesian_optimization</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>test_function</span><span class=p>,</span> <span class=n>bounds</span><span class=p>,</span> <span class=n>n_init</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>n_iter</span><span class=o>=</span><span class=mi>12</span><span class=p>,</span> <span class=n>acq_func</span><span class=o>=</span><span class=s2>&#34;ei&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 最適化結果のプロット</span>
</span></span><span class=line><span class=cl><span class=n>X_plot</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>bounds</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>bounds</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=mi>300</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y_true</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>test_function</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>X_plot</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>mu</span><span class=p>,</span> <span class=n>var</span> <span class=o>=</span> <span class=n>gp</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_plot</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>sigma</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>var</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># GP代理モデル</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>X_plot</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=s2>&#34;k--&#34;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;True function&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>X_plot</span><span class=p>,</span> <span class=n>mu</span><span class=p>,</span> <span class=s2>&#34;b-&#34;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;GP mean&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>fill_between</span><span class=p>(</span><span class=n>X_plot</span><span class=o>.</span><span class=n>ravel</span><span class=p>(),</span> <span class=n>mu</span> <span class=o>-</span> <span class=mi>2</span><span class=o>*</span><span class=n>sigma</span><span class=p>,</span> <span class=n>mu</span> <span class=o>+</span> <span class=mi>2</span><span class=o>*</span><span class=n>sigma</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                     <span class=n>alpha</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;blue&#34;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;95% CI&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X_sample</span><span class=p>[:</span><span class=mi>3</span><span class=p>],</span> <span class=n>y_sample</span><span class=p>[:</span><span class=mi>3</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=n>c</span><span class=o>=</span><span class=s2>&#34;green&#34;</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>80</span><span class=p>,</span> <span class=n>zorder</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Initial points&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X_sample</span><span class=p>[</span><span class=mi>3</span><span class=p>:],</span> <span class=n>y_sample</span><span class=p>[</span><span class=mi>3</span><span class=p>:],</span>
</span></span><span class=line><span class=cl>                <span class=n>c</span><span class=o>=</span><span class=s2>&#34;red&#34;</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>80</span><span class=p>,</span> <span class=n>zorder</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;BO samples&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s2>&#34;x&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s2>&#34;f(x)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s2>&#34;Bayesian Optimization with GP Surrogate&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># EI獲得関数</span>
</span></span><span class=line><span class=cl><span class=n>acq_ei</span> <span class=o>=</span> <span class=n>expected_improvement</span><span class=p>(</span><span class=n>mu</span><span class=p>,</span> <span class=n>var</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=n>y_sample</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>X_plot</span><span class=p>,</span> <span class=n>acq_ei</span><span class=p>,</span> <span class=s2>&#34;r-&#34;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;EI&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s2>&#34;x&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s2>&#34;EI(x)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s2>&#34;Expected Improvement&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s2>&#34;bayesian_optimization_result.png&#34;</span><span class=p>,</span> <span class=n>dpi</span><span class=o>=</span><span class=mi>150</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>best_idx</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmin</span><span class=p>(</span><span class=n>y_sample</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Best x: </span><span class=si>{</span><span class=n>X_sample</span><span class=p>[</span><span class=n>best_idx</span><span class=p>]</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Best f(x): </span><span class=si>{</span><span class=n>y_sample</span><span class=p>[</span><span class=n>best_idx</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Total evaluations: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>y_sample</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><img src=/posts/20260223_bayesian_optimization/bayesian_optimization_result.png alt=ベイズ最適化の結果></p><p>GPの予測平均（青線）が真の関数（黒点線）に近づいていく様子と、信頼区間（青い帯）がデータ付近で狭くなる様子が確認できます。EIは不確実性が高く改善が期待される領域で大きな値をとり、探索と活用のバランスを自動的に調整します。</p><h2 id=cemmppiとの比較>CEM・MPPIとの比較</h2><p>ベイズ最適化は<a href=https://yuhi-sa.github.io/posts/20210329_cem/1/>クロスエントロピー法（CEM）</a>や<a href=https://yuhi-sa.github.io/posts/20260215_mppi/1/>MPPI</a>とは異なるアプローチの最適化手法です。以下に比較をまとめます。</p><table><thead><tr><th></th><th>ベイズ最適化</th><th>CEM</th><th>MPPI</th></tr></thead><tbody><tr><td>評価バジェット</td><td>非常に少数（数十回）</td><td>中程度（数百〜数千回）</td><td>中程度（数百〜数千回）</td></tr><tr><td>並列化</td><td>逐次的（バッチ拡張可）</td><td>高い</td><td>高い</td></tr><tr><td>勾配不要</td><td>はい</td><td>はい</td><td>はい</td></tr><tr><td>代理モデル</td><td>あり（GP）</td><td>なし</td><td>なし</td></tr><tr><td>探索戦略</td><td>獲得関数による</td><td>エリートサンプル選択</td><td>指数関数的重み付け</td></tr><tr><td>主な用途</td><td>ハイパーパラメータ最適化</td><td>組合せ最適化、計画</td><td>リアルタイム制御</td></tr><tr><td>スケーラビリティ</td><td>低次元（〜20次元）</td><td>高次元も可能</td><td>高次元も可能</td></tr></tbody></table><ul><li><strong>ベイズ最適化</strong>は1回の評価が高コストな場合に最適です。代理モデルにより少ない評価回数で効率的に探索しますが、ガウス過程の計算コストにより高次元への適用が難しくなります。</li><li><strong>CEM</strong>はサンプルベースの手法で、多数の評価が可能な場合に有効です。エリートサンプルのハードな選択により分布を更新します。</li><li><strong>MPPI</strong>はCEMと同様にサンプルベースですが、ソフトな重み付けにより全サンプルの情報を活用します。リアルタイムの制御問題に適しています。</li></ul><h2 id=参考文献>参考文献</h2><ul><li>Rasmussen, C. E., & Williams, C. K. I. (2006). <em>Gaussian Processes for Machine Learning</em>. MIT Press.</li><li>Shahriari, B., et al. (2016). &ldquo;Taking the Human Out of the Loop: A Review of Bayesian Optimization.&rdquo; <em>Proceedings of the IEEE</em>, 104(1), 148-175.</li><li>Snoek, J., Larochelle, H., & Adams, R. P. (2012). &ldquo;Practical Bayesian Optimization of Machine Learning Algorithms.&rdquo; <em>NeurIPS 2012</em>.</li><li>Brochu, E., Cora, V. M., & de Freitas, N. (2010). &ldquo;A Tutorial on Bayesian Optimization of Expensive Cost Functions.&rdquo; <em>arXiv:1012.2599</em>.</li></ul></div><div class="ad-slot in-content my-3"><ins class=adsbygoogle style=display:block;text-align:center data-ad-layout=in-article data-ad-format=fluid data-ad-client=ca-pub-9558545098866170></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><footer class=article-footer></footer><meta itemprop=wordCount content="781"><meta itemprop=url content="https://yuhi-sa.github.io/posts/20260223_bayesian_optimization/1/"></article><nav class="post-nav mt-5" aria-label="Post navigation"><a href=/posts/20260215_mppi/1/ class="post-nav__item post-nav__item--prev"><span class="post-nav__label text-muted"><i class="fas fa-arrow-left me-1" aria-hidden=true></i>前の記事
</span><span class=post-nav__title>MPPI（Model Predictive Path Integral）の数理：クロスエントロピー法との統一的理解</span>
</a><a href=/posts/20260223_lowpass_filter/1/ class="post-nav__item post-nav__item--next"><span class="post-nav__label text-muted">次の記事<i class="fas fa-arrow-right ms-1" aria-hidden=true></i>
</span><span class=post-nav__title>ローパスフィルタの設計と比較：移動平均・バターワース・チェビシェフ</span></a></nav><section class="related-posts mt-5" aria-label="Related posts"><h2 class=related-posts__title>関連記事</h2><div class=related-posts__grid><article class=related-posts__item><h3 class=related-posts__item-title><a href=/posts/20260226_sgd_adam/1/>確率的勾配降下法からAdamまで：勾配ベース最適化の進化</a></h3><div class=card-meta><time datetime=2026-02-26>February 26, 2026</time></div></article><article class=related-posts__item><h3 class=related-posts__item-title><a href=/posts/20260215_mppi/1/>MPPI（Model Predictive Path Integral）の数理：クロスエントロピー法との統一的理解</a></h3><div class=card-meta><time datetime=2026-02-15>February 15, 2026</time></div></article><article class=related-posts__item><h3 class=related-posts__item-title><a href=/posts/20210108_bayes/1/>ベイズ線形回帰の基礎：最小二乗法からベイズ推定まで</a></h3><div class=card-meta><time datetime=2021-01-08>January 8, 2021</time></div></article></div></section><nav class="article-navigation mt-4" aria-label="Article navigation"><a href=/posts/ class="btn btn-outline-secondary btn-sm mb-3"><i class="fas fa-arrow-left me-1" aria-hidden=true></i>
Back to posts</a><nav aria-label="Breadcrumb navigation" class=breadcrumb-nav role=navigation><ol class=breadcrumb itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumb-item itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=/ itemprop=item aria-label="Navigate to homepage"><i class="fas fa-home" aria-hidden=true></i>
<span itemprop=name>tomato blog</span>
</a><meta itemprop=position content="1"></li><li class=breadcrumb-item itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=https://yuhi-sa.github.io/ itemprop=item aria-label="Navigate to tomato blog"><span itemprop=name>tomato blog</span>
</a><meta itemprop=position content="2"></li><li class=breadcrumb-item itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=https://yuhi-sa.github.io/posts/ itemprop=item aria-label="Navigate to Posts"><span itemprop=name>Posts</span>
</a><meta itemprop=position content="3"></li><li class="breadcrumb-item active" aria-current=page itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><span itemprop=name>ベイズ最適化の基礎とPython実装</span>
<meta itemprop=position content="4"></li></ol></nav></nav></div></div></div></main><footer role=contentinfo class=site-footer><div class="container pt-4 pb-3" style="border-top:2px solid var(--accent,#e54d2e)"><div class="row justify-content-center"><div class="col-md-8 text-center"><p class="copyright-text text-muted mb-2">&copy; 2026 yuhi-sa. All rights reserved.</p><p class="theme-attribution text-muted small mt-2 mb-0">Powered by
<a href=https://gohugo.io/ target=_blank rel=noopener class=text-decoration-none>Hugo</a>
with
<a href=https://github.com/yuhi-sa/tomatohugo target=_blank rel=noopener class=text-decoration-none>TomatoHugo</a></p></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js integrity=sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz crossorigin=anonymous defer></script><script src=/js/dark-mode.min.3e457dc8346f064bee795e6f9b73e1516dcd059e750c521fe4b445f9ea9a7821.js integrity="sha256-PkV9yDRvBkvueV5vm3PhUW3NBZ51DFIf5LRF+eqaeCE=" defer></script><script>window.addEventListener("load",function(){const e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3",document.head.appendChild(e),e.onload=function(){window.dataLayer=window.dataLayer||[];function e(){dataLayer.push(arguments)}e("js",new Date),e("config","G-LN6QP6VVM3")}})</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebPage","name":"ベイズ最適化の基礎とPython実装","url":"https:\/\/yuhi-sa.github.io\/posts\/20260223_bayesian_optimization\/1\/","description":"ベイズ最適化のアルゴリズムをPythonで実装します。ガウス過程回帰の基礎から獲得関数（EI, UCB, PI）の数式、1D関数での最適化デモまで解説します。","inLanguage":"ja","isPartOf":{"@type":"WebSite","name":"tomato blog","url":"https:\/\/yuhi-sa.github.io\/"}}</script></body></html>