<!doctype html><html lang=ja dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><meta name=robots content="index,follow"><meta property="og:title" content="EMアルゴリズム2(変分下界とKLダイバージェンス) | tomato blog"><title>EMアルゴリズム2(変分下界とKLダイバージェンス) | tomato blog</title>
<link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css rel=stylesheet><link rel=stylesheet href=/css/main.min.cbcf0adf3096d54322591302ca01248346902aa2474afcbd71c3a1b999e09ad9.css integrity="sha256-y88K3zCW1UMiWRMCygEkg0aQKqJHSvy9ccOhuZngmtk=" crossorigin=anonymous><link rel=stylesheet href=/css/syntax.min.aa0332253f313dc48905008b4ab314155e5a13302588d25bcf4949f7c1abdde0.css integrity="sha256-qgMyJT8xPcSJBQCLSrMUFV5aEzAliNJbz0lJ98Gr3eA=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js></script><script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script></head><body><header><nav class="navbar navbar-expand-lg navbar-light bg-light"><div class=navbar-brand style=padding-left:10px>tomato blog</div><button class="navbar-toggler ml-auto" type=button data-bs-toggle=collapse data-bs-target=#navbarNav aria-controls=navbarNav aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarNav><ul class="navbar-nav ml-auto"><li class=nav-item><a zgotmplz href=https://yuhi-sa.github.io/ class=nav-link>Blog</a></li><li class=nav-item><a zgotmplz href=https://yuhi-sa.github.io/tags class=nav-link>Tags</a></li><li class=nav-item><a zgotmplz href=https://yuhi-sa.github.io/posts/about class=nav-link>About</a></li><li class=nav-item><a zgotmplz href=https://yuhi-sa.github.io/posts/privacy_policy class=nav-link>Privacy policy</a></li></ul></div></nav><script async src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-LN6QP6VVM3")</script><script data-ad-client=ca-pub-9558545098866170 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></header><main><div style="max-width:80%;margin:0 auto"><h1 id=emアルゴリズム2変分下界とklダイバージェンス>EMアルゴリズム2(変分下界とKLダイバージェンス)</h1><p>EステップとMステップを繰り返すだけで，EMアルゴリズムがうまく推定できる理由について理解するために，変分下界とKLダイバージェンスという概念を導入する．</p><h2 id=変分下界>変分下界</h2><p>EMアルゴリズムにおける変分下界は以下のように定義される．</p><p>$$\mathcal{B}(\theta,\hat{\theta})=\int p(z|x,\hat{\theta}) \log \frac{p(x,z|\theta)}{p(z|x,\hat{\theta})}dz$$</p><p>変分下界の式を変形する</p><p>$$\mathcal{B}(\theta,\hat{\theta})=\log p(x|\theta)-(\int p(z|x,\hat{\theta}\log\frac{p(z|x,\hat{\theta})}{p(z|x,\theta)}dz)$$</p><p>これは第一項が，対数尤度，第二項がKLダイバージェンスを表している．
これにより変分下界はQ関数とエントロピーの和となっていることがわかる．</p><p>$$\mathcal{B}(\theta,\hat{\theta})= Q(\theta,\hat{\theta})+H(p(z|x,\hat{\theta}))$$</p><h3 id=klダイバージェンス>KLダイバージェンス</h3><p>KLダイバージェンス$\mathcal{D}(q||p)$は，分布qと分布pの比の対数の期待値として定義され，分布どうしの距離を測るために使われる．</p><p>$$\mathcal{D}(q||p)=\mathbb{E}[\log\frac{q}{p}]\int q(x)\log \frac{q(x)}{p(x)}dx$$</p><p>2つの分布が類似しているほどKLダイバージェンスは小さくなり，完全に一致する場合0となる．また，Jensenの不等式より非負性が証明されている．</p><p><img style="max-width:50%;height:auto;display:block;margin:0 auto" alt=変分下界 src=./../%E5%A4%89%E5%88%86%E4%B8%8B%E7%95%8C.png></p><ul><li>$\hat{\theta}$の更新
分布が一致し，KLダイバージェンスが0になるため変分下界$\mathcal{B}$が増加する．</li><li>$\theta$の更新
Q関数を最大化することにより，変分下界$\mathcal{B}$も増加する．エントロピー$H$は$\theta$が含まれないため変化しない．</li></ul><p>以上より，EMアルゴリズムによって変分下界が増加していく．変分下界とKLダイバージェンスの和である対数尤度は常に変分下界より大きいため，対数尤度も増加していく．よってEMアルゴリズムは対数尤度を増加させる．</p><h2 id=参考>参考</h2><ul><li>手塚 太郎，"<a href=https://amzn.to/3cCILQM>しくみがわかるベイズ統計と機械学習</a>"</li></ul></div><div><div>Tags:</div><ul><li><a href=/tags/%E3%81%97%E3%81%8F%E3%81%BF%E3%81%8C%E3%82%8F%E3%81%8B%E3%82%8B%E3%83%99%E3%82%A4%E3%82%BA%E7%B5%B1%E8%A8%88%E3%81%A8%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/>しくみがわかるベイズ統計と機械学習</a></li></ul></div><nav aria-label=breadcrumb><ol class=breadcrumb><li class=breadcrumb-item><a href=/>Home</a></li><li class="breadcrumb-item active" aria-current=page>EMアルゴリズム2(変分下界とKLダイバージェンス)</li></ol></nav></main><footer><p style=text-align:center>Copyright 2024. All rights reserved.</p></footer><link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css rel=stylesheet><link rel=stylesheet href=/css/main.min.cbcf0adf3096d54322591302ca01248346902aa2474afcbd71c3a1b999e09ad9.css integrity="sha256-y88K3zCW1UMiWRMCygEkg0aQKqJHSvy9ccOhuZngmtk=" crossorigin=anonymous><link rel=stylesheet href=/css/syntax.min.aa0332253f313dc48905008b4ab314155e5a13302588d25bcf4949f7c1abdde0.css integrity="sha256-qgMyJT8xPcSJBQCLSrMUFV5aEzAliNJbz0lJ98Gr3eA=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js></script><script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script></body></html>