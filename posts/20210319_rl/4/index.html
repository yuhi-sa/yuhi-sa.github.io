<!DOCTYPE html>
<html lang="ja"
  dir="ltr">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="robots" content="index,follow">


<meta name="description" content="勉強したことなどをメモしています">


<link rel="canonical" href="http://localhost:1313/posts/20210319_rl/4/">


<meta property="og:type" content="article">
<meta property="og:title" content="ニューラルネットワークを適用した強化学習">
<meta property="og:description" content="勉強したことなどをメモしています">
<meta property="og:url" content="http://localhost:1313/posts/20210319_rl/4/">
<meta property="og:site_name" content="tomato blog">
<meta property="og:image" content="https://yuhi-sa.github.io/ogp.jpeg">
<meta property="article:published_time" content="2021-03-22T10:00:23&#43;09:00">
<meta property="article:modified_time" content="2021-03-22T10:00:23&#43;09:00">
<meta property="article:tag" content="強化学習"><meta property="article:tag" content="深層学習">


<meta name="twitter:card" content="summary_large_image">

<meta name="twitter:title" content="ニューラルネットワークを適用した強化学習">
<meta name="twitter:description" content="勉強したことなどをメモしています">
<meta name="twitter:image" content="https://yuhi-sa.github.io/ogp.jpeg">


<title>ニューラルネットワークを適用した強化学習 | tomato blog</title>



<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "ニューラルネットワークを適用した強化学習",
  "description": "",
  "author": {
    "@type": "Person",
    "name": ""
  },
  "publisher": {
    "@type": "Organization",
    "name": "tomato blog",
    
    "url": "http:\/\/localhost:1313\/"
  },
  "datePublished": "2021-03-22T10:00:23\u002b09:00",
  "dateModified": "2021-03-22T10:00:23\u002b09:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http:\/\/localhost:1313\/posts\/20210319_rl\/4\/"
  },
  
  "url": "http:\/\/localhost:1313\/posts\/20210319_rl\/4\/",
  "wordCount":  103 ,
  "keywords": [
    "強化学習", "深層学習"
  ],
  "articleSection": "posts"
}
</script>




<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw==" crossorigin="anonymous" referrerpolicy="no-referrer">


<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">




  <link rel="stylesheet" href="/css/_variables.css">

  <link rel="stylesheet" href="/css/main.css">

  <link rel="stylesheet" href="/css/syntax.css">





<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>



<script src="/js/dark-mode.min.js"></script>


<script src="/js/copy-code.min.js"></script>


</head>

<body itemscope itemtype="https://schema.org/WebPage">
  <a href="#main-content" class="sr-only sr-only-focusable">Skip to main content</a>
  
  <header role="banner">
    <nav class="navbar navbar-expand-lg navbar-light bg-light" role="navigation" aria-label="Main navigation">
  <div class="container">
    
  <a class="navbar-brand" href="http://localhost:1313/">tomato blog</a>
  <button class="navbar-toggler d-lg-none" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav ms-auto">
  <li class="nav-item mx-2">
    <a class="nav-link" href="http://localhost:1313/">Blog</a>
  </li>
  <li class="nav-item mx-2">
    <a class="nav-link" href="http://localhost:1313/tags/">Tags</a>
  </li>
  <li class="nav-item mx-2">
    <a class="nav-link" href="http://localhost:1313/posts/about/">About</a>
  </li>
  <li class="nav-item mx-2">
    <a class="nav-link" href="http://localhost:1313/posts/privacy_policy/">Privacy policy</a>
  </li>

      <li class="nav-item">
        <button id="darkModeToggle" class="nav-link btn btn-link border-0" type="button" aria-label="Toggle dark mode">
          <i class="fas fa-moon" id="darkModeIcon"></i>
          <span class="d-lg-none ms-2">ダークモード</span>
        </button>
      </li>
    </ul>
  </div>

    
    
    
  </div>
</nav>

  
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-LN6QP6VVM3');
  </script>



  
  <script data-ad-client="ca-pub-9558545098866170" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>



  </header>
  
  <main id="main-content" role="main">
    
<div class="container">
  <article itemscope itemtype="https://schema.org/Article">
    
    <header class="article-header">
      <h1 itemprop="headline">ニューラルネットワークを適用した強化学習</h1>
      
      
      
      <div class="article-meta">
        <time datetime="2021-03-22T10:00:23&#43;09:00" itemprop="datePublished">
          <i class="far fa-calendar-alt" aria-hidden="true"></i>
          March 22, 2021
        </time>
        
        
        
        
        
        
        <span aria-label="Reading time">
          <i class="far fa-clock" aria-hidden="true"></i>
          1 min read
        </span>
        
      </div>
      
      
      <div class="article-tags" role="group" aria-label="Article tags">
        
        <a href="/tags/%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92/" 
           class="badge badge-custom" 
           rel="tag"
           itemprop="keywords">
          強化学習
        </a>
        
        <a href="/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/" 
           class="badge badge-custom" 
           rel="tag"
           itemprop="keywords">
          深層学習
        </a>
        
      </div>
      
    </header>
    
    
    
    
    
    <div class="article-content" itemprop="articleBody">
      <h1 id="ニューラルネットワークを適用した強化学習">ニューラルネットワークを適用した強化学習</h1>
<p>強化学習において、状態空間や行動空間が非常に大きい場合、価値関数や方策をテーブル形式で表現することが困難になります。このような場合に、ニューラルネットワーク（NN）を用いて価値関数や方策を近似する手法が用いられます。</p>
<p>しかし、NNを強化学習に適用する際には、学習が不安定になりやすいという課題があります。これを解決するために、様々な工夫が提案されています。</p>
<h2 id="学習安定化のための主要な工夫">学習安定化のための主要な工夫</h2>
<h3 id="1-experience-replay-経験再生">1. Experience Replay (経験再生)</h3>
<p>エージェントが環境と相互作用して得た経験（状態、行動、報酬、次の状態）を<strong>リプレイバッファ</strong>と呼ばれるメモリに蓄積します。学習時には、このリプレイバッファからランダムに経験のミニバッチをサンプリングしてNNを更新します。</p>
<ul>
<li><strong>効果</strong>:
<ul>
<li>経験間の相関を低減し、学習の安定性を向上させます。</li>
<li>同じ経験を複数回利用できるため、データの利用効率が向上します。</li>
</ul>
</li>
</ul>
<h3 id="2-fixed-target-q-network-固定ターゲットqネットワーク">2. Fixed Target Q-Network (固定ターゲットQネットワーク)</h3>
<p>Q学習において、ターゲット値（目標となるQ値）の計算に用いるQネットワークのパラメータを、一定期間固定する手法です。</p>
<ul>
<li><strong>課題</strong>: 通常のQ学習では、ターゲットQ値の計算と、Qネットワークの更新に同じネットワークが使われるため、目標値が常に変動し、学習が不安定になりやすいです。</li>
<li><strong>効果</strong>: ターゲットQネットワークのパラメータを固定することで、目標値が安定し、学習の収束性が向上します。一定のステップごとにターゲットQネットワークのパラメータをメインのQネットワークのパラメータで更新します。</li>
</ul>
<h3 id="3-reward-clipping-報酬のクリッピング">3. Reward Clipping (報酬のクリッピング)</h3>
<p>報酬のスケールが非常に大きい場合や、報酬の分布が偏っている場合に、報酬を一定の範囲（例: [-1, 1]）にクリッピングする手法です。</p>
<ul>
<li><strong>効果</strong>: 報酬のスケールが大きすぎることによる勾配の不安定化を防ぎ、学習を安定させます。</li>
</ul>
<h2 id="deep-q-network-dqn-とその改良">Deep Q-Network (DQN) とその改良</h2>
<p><strong>Deep Q-Network (DQN)</strong> は、Q学習に深層学習（ニューラルネットワーク）と上記の安定化技術（Experience Replay, Fixed Target Q-Network）を組み合わせた画期的な手法です。Google DeepMindが開発し、Atariゲームで人間を超える性能を示しました。</p>
<p>DQNの発表以降、さらなる性能向上を目指して様々な改良手法が提案されています。DeepMindは、これらの改良手法のいくつかを組み合わせた「<strong>Rainbow</strong>」というモデルも発表しています。</p>
<h3 id="dqnの主な改良手法">DQNの主な改良手法</h3>
<ol>
<li>
<p><strong>Double DQN (DDQN)</strong></p>
<ul>
<li><strong>目的</strong>: Q値の過大評価を抑制し、価値の見積もり精度を向上させます。</li>
<li><strong>仕組み</strong>: 行動選択とターゲットQ値の計算に用いるネットワークを分離します。行動選択はメインのQネットワークで行い、その行動のターゲットQ値はターゲットQネットワークで計算します。</li>
</ul>
</li>
<li>
<p><strong>Prioritized Experience Replay (PER)</strong></p>
<ul>
<li><strong>目的</strong>: 学習効率を向上させます。</li>
<li><strong>仕組み</strong>: Experience Replayにおいて、単にランダムに経験をサンプリングするのではなく、TD誤差が大きい（つまり、学習効果が高い）経験を優先的にサンプリングします。</li>
</ul>
</li>
<li>
<p><strong>Dueling Network Architectures (Dueling DQN)</strong></p>
<ul>
<li><strong>目的</strong>: 価値の見積もり精度を向上させます。</li>
<li><strong>仕組み</strong>: Q値を「状態価値 (State-Value)」と「アドバンテージ (Advantage)」に分解して計算するネットワーク構造を採用します。これにより、各行動の価値をより正確に評価できるようになります。</li>
</ul>
</li>
<li>
<p><strong>Multi-step Learning (N-step TD)</strong></p>
<ul>
<li><strong>目的</strong>: 価値の見積もり精度を向上させます。</li>
<li><strong>仕組み</strong>: Q学習やSARSAのような1ステップTD更新ではなく、nステップ先の報酬と価値の見積もりを用いて更新を行います。モンテカルロ法とTD法の中間的な性質を持ちます。</li>
</ul>
</li>
<li>
<p><strong>Distributional RL (C51, QR-DQNなど)</strong></p>
<ul>
<li><strong>目的</strong>: 価値の見積もり精度を向上させます。</li>
<li><strong>仕組み</strong>: Q値を単一の値として推定するのではなく、報酬の分布そのものを学習します。これにより、より豊かな情報に基づいて行動を決定できるようになります。</li>
</ul>
</li>
<li>
<p><strong>Noisy Nets</strong></p>
<ul>
<li><strong>目的</strong>: 探索効率を向上させます。</li>
<li><strong>仕組み</strong>: ε-Greedy法のように手動で ε を設定する代わりに、ネットワークの重みにノイズを加えることで、エージェント自身が探索の度合いを学習できるようにします。これにより、探索のバランス調整が自動化されます。</li>
</ul>
</li>
</ol>
<h2 id="参考">参考</h2>
<ul>
<li>久保隆宏, 『Pythonで学ぶ強化学習 入門から実践まで』, 翔栄社 (2019)</li>
</ul>
    </div>
    
    
    <footer class="article-footer">
      
    </footer>
    
    
    <meta itemprop="wordCount" content="103">
    <meta itemprop="url" content="http://localhost:1313/posts/20210319_rl/4/">
  </article>
  
  
  <nav class="article-navigation" aria-label="Article navigation">
    <nav aria-label="breadcrumb" class="breadcrumb-nav">
  <ol class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
    <li class="breadcrumb-item" 
        itemprop="itemListElement" 
        itemscope 
        itemtype="https://schema.org/ListItem">
      <a href="/" itemprop="item">
        <i class="fas fa-home" aria-hidden="true"></i>
        <span itemprop="name">Home</span>
      </a>
      <meta itemprop="position" content="1" />
    </li>
        <li class="breadcrumb-item" 
            itemprop="itemListElement" 
            itemscope 
            itemtype="https://schema.org/ListItem">
          <a href="http://localhost:1313/" itemprop="item">
            <span itemprop="name">tomato blog</span>
          </a>
          <meta itemprop="position" content="2" />
        </li>
        <li class="breadcrumb-item" 
            itemprop="itemListElement" 
            itemscope 
            itemtype="https://schema.org/ListItem">
          <a href="http://localhost:1313/posts/" itemprop="item">
            <span itemprop="name">Posts</span>
          </a>
          <meta itemprop="position" content="3" />
        </li>
      
      <li class="breadcrumb-item active" 
          aria-current="page" 
          itemprop="itemListElement" 
          itemscope 
          itemtype="https://schema.org/ListItem">
        <span itemprop="name">ニューラルネットワークを適用した強化学習</span>
        <meta itemprop="position" content="4" />
      </li>
  </ol>
</nav>
</nav>
  
    
  <div class="mt-3">
    <h6 class="d-inline-block me-2">Tags:</h6>
      <a href="/tags/%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92/" class="badge badge-custom text-decoration-none me-1">強化学習</a>
      <a href="/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/" class="badge badge-custom text-decoration-none me-1">深層学習</a>
  </div>

  </nav>
</div>

  </main>
  
  <footer role="contentinfo">
    <div class="container py-4">
  <div class="row justify-content-center">
    <div class="col-md-6 text-center">
      <p class="text-muted mb-0">Copyright &copy; 2025. All rights reserved.</p>
    </div>
  </div>
</div>

  </footer>
  
  



<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>



<script src="/js/dark-mode.min.js"></script>


<script src="/js/copy-code.min.js"></script>

</body>

</html>
