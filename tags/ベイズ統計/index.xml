<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ベイズ統計 on tomato blog</title>
    <link>https://yuhi-sa.github.io/tags/%E3%83%99%E3%82%A4%E3%82%BA%E7%B5%B1%E8%A8%88/</link>
    <description>Recent content in ベイズ統計 on tomato blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Fri, 08 Jan 2021 15:17:23 +0900</lastBuildDate>
    <atom:link href="https://yuhi-sa.github.io/tags/%E3%83%99%E3%82%A4%E3%82%BA%E7%B5%B1%E8%A8%88/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[Python]ベイズ推定に基づく線形回帰(最小二乗推定，最尤推定，MAP推定，ベイズ推定)</title>
      <link>https://yuhi-sa.github.io/posts/20210108_bayes/1/</link>
      <pubDate>Fri, 08 Jan 2021 15:17:23 +0900</pubDate>
      <guid>https://yuhi-sa.github.io/posts/20210108_bayes/1/</guid>
      <description>背景 回帰問題の目的は，$N$個の観測値と対応する目標値からなる訓練データ集合が与えられたとき，新しい観測値に対する目標値の値を予測することである．今回扱う線形回帰モデルは，多項式は調節可能なパラメータの線形結合という特徴を利用した最も単純なモデルである．固定された基底関数の入力変数に関して非線型な関数の固定された集合結合をとることにより，有用な関数のクラスが得られる．&#xA;観測されたデータ$D={(x_i,y_i);i=1,2,&amp;hellip;,n}$に対して，基底関数の線形結合に基づく回帰関数モデルを以下のように定義する．ここで$\Phi$を$x$の基底関数，$\epsilon$を誤差項とする．&#xA;$$ y_i= \Phi w+ \epsilon $$&#xA;ベイズ線形回帰について 最小二乗推定 最小二乗推定は，回帰モデルによる予測誤差の二乗和$S(w)$を最小化する$\hat{w}$を求める手法である．$S(w)$を$w$で偏微分し，$\hat{w}$を求める．&#xA;$$ S(w)=\epsilon^{T}\epsilon=(y-\Phi w)^T(y-\Phi w) $$&#xA;$$ \frac{dS(w)}{dw}=-\Phi^{T}y+\Phi^T\Phi w $$ $\frac{dS(w)}{dw}=0$のときを考えると，&#xA;$$ \hat{w}=(\Phi^T\Phi)^{-1}\Phi^{T}y $$ 従って，最小二乗推定による予測モデルは以下のようになる．&#xA;$$ \hat{y}=\Phi\hat{w}=\Phi(\Phi^T\Phi)^{-1}y $$&#xA;最尤推定 最尤推定は，尤度$P(y,w)$を最大化する$\hat{w}$を求める手法である．誤差項に正規分布を仮定したモデルを考える．このとき観測値$y$は平均$\Phi w$，分散行列$\sigma^2I_n$のn次元正規分布に従う．よって尤度は，以下のように与えられる．&#xA;$$ y= \Phi w+ \epsilon,\epsilon \sim \mathcal{N}(0,\sigma^2I_n) $$ $$ P(y\mid w,\sigma^2)=\mathcal{N}(\Phi w,\sigma^2I_n) =\frac{1}{(2\pi\sigma^2)^{\frac{n}{2}}}exp{-\frac{1}{2\sigma^2}(y-\Phi w)^T(y-\Phi w)} $$&#xA;$P(y\mid w)$の対数を$w$で偏微分し，$\hat{w}$を求める．&#xA;$$ \log P(y\mid w) = -\frac{n}{2}\log(2\pi\sigma^2)-\frac{(y-\Phi w)^T(y-\Phi w)}{2\sigma^2} $$&#xA;$$ \frac{1}{P(y\mid w)}\frac{P(y\mid w)}{dw}=-(\Phi^{T}y+\Phi^{T}\Phi w) $$ $\frac{dP(y\mid w)}{dw}=0$のときを考えると．&#xA;$$ \hat{w}=(\Phi^T\Phi)^{-1}\Phi^{T}y $$</description>
    </item>
  </channel>
</rss>
