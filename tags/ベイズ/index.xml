<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ベイズ on とまとまとブログ</title>
    <link>https://yuhi-sa.github.io/tags/%E3%83%99%E3%82%A4%E3%82%BA/</link>
    <description>Recent content in ベイズ on とまとまとブログ</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 16 Mar 2021 15:00:23 +0900</lastBuildDate><atom:link href="https://yuhi-sa.github.io/tags/%E3%83%99%E3%82%A4%E3%82%BA/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ラグランジュの未定数法</title>
      <link>https://yuhi-sa.github.io/posts/202103bayes/7/</link>
      <pubDate>Tue, 16 Mar 2021 15:00:23 +0900</pubDate>
      
      <guid>https://yuhi-sa.github.io/posts/202103bayes/7/</guid>
      <description>制約付き最適化のうち，制約条件が等式で合わされる場合によく用いられるのがラグランジュの未定乗数法である．
２接線が重なる点を求めるには勾配を求めることが有効である． 勾配は勾配作用素$\nabla$を用いて以下のように定義される．
$$\nabla f = (\frac{df}{dx}, \frac{df}{dy})$$
目的関数fを制約gのもとで解くことくを考えると．
$$\nabla f(\mu) = \lambda \nabla g(\mu)$$
が成り立ち，$\mu$が制約付き最適化の答えの候補となる． ここで，$\lambda$はラグランジュ未定乗数と呼ばれる．
ラグランジュ関数を以下のように定義すると，
$$\mathcal{L}(\mu,\lambda)=f(\mu)-\lambda g(\mu)$$
ラグランジュの未定乗数法は，$\nabla \mathcal{L}=0$を満たす$\mu$と$\lambda$，すなわちラグランジュ関数の勾配が0になる変数の値を見つけることとなる．
例1 $g(x,y)=2x+y+1=0$という制約条件を満たすx,yで$f(x,y)=x^2+y^2$を最小化するものを求める．
$$\nabla f(x,y) = (2x,2y)$$
$$\lambda \nabla g(x,y) = (2\lambda, \lambda)$$
よって，
 $2x = 2\lambda$ $2y = \lambda$  さらに$g(x,y)=2x+y+1=0$を用いて計算すると，$x=-2/5,y=-1/5,$となる．
多項分布の最尤推定 ラグランジュの未定乗数法を多項分布の最尤推定に利用する．この場合，fは多項分布の対数，gは制約からくる$\sum_{j=1}^k\mu_j-1$となる．
$$f= \frac{(\sum_{j=1}^kx_j)!}{\Pi_{j=1}^kx_j!}\Pi_{j=1}^k\mu_j^{x_j}$$
$$g=\sum_{j=1}^k\mu_j-1$$
ラグランジュの未定乗数法より
$$\nabla (\frac{(\sum_{j=1}^kx_j)!}{\Pi_{j=1}^kx_j!}\Pi_{j=1}^k\mu_j^{x_j})=\lambda \nabla(\sum_{j=1}^k\mu_j-1)$$
両辺を$\hat{\mu}_h$で微分すると
$$\frac{x_h}{\hat{\mu}_h}=\lambda$$
制約条件を用いて$\lambda$を求めると
$$\lambda = \sum_{h=1}^k \hat{\mu}_h=m(試行の総和)$$
したがって，
$$\hat{\mu}_j=\frac{x_j}{\lambda}= \frac{x_j}{m}$$
参考  手塚 太郎，&amp;quot;しくみがわかるベイズ統計と機械学習&amp;quot;  </description>
    </item>
    
    <item>
      <title>共役事前分布</title>
      <link>https://yuhi-sa.github.io/posts/202103bayes/8/</link>
      <pubDate>Tue, 16 Mar 2021 15:00:23 +0900</pubDate>
      
      <guid>https://yuhi-sa.github.io/posts/202103bayes/8/</guid>
      <description>事後分布の式がシンプルになるように，以下の共役事前分布を用いることが標準的となっている．
ディリクレ分布 多項分布に対する共役事前分布はディリクレ分布$\mathcal{D}(\mu|\alpha)$である．
$$\mathcal{D}(\mu|\alpha)= \frac{\Gamma(\sum_{j=1}^{k}\alpha_j)}{\Pi_{j=1}^k\Gamma(\alpha_j)}\Pi_{j=1}^k\mu_j^{\alpha_j-1}$$
ここで，$\alpha$はディリクレ分布のパラメータであり，$\Gamma$は以下に示すガンマ関数である．
$$\Gamma(x)=\int_0^\infty t^{x-1}e^{-t}dt$$
ベータ分布 二項分布の事前分布として使えるのがベータ分布である．
$$p(\mu|a,b)=\frac{1}{B(a,b)}\mu^{\alpha-1}(1-\mu)^{b-1}$$
ここで，$B(a,b)$は2次元の多項ベータ関数を表す．
$$B(a,b)=\int_0^1\mu^{a-1}(1-\mu)^{b-1}d\mu$$
ガンマ分布 観測値が正規分布$\mathcal{N}(x|\mu,\sigma^2)$に従うとする時，その平均パラメータ$\mu$に対してベイズ推定を行うための共役事前分布としては正規分布$\mathcal{N}(\mu|\Psi,\rho^2)$が使える． 分散$\sigma^2$に対してベイズ推定を行う場合を考える． $\sigma^2$の事前分布として正規分布$\mathcal{N}(\sigma^2|\phi,\eta^2)$を使うと，事後分布は事前分布と同じ関係式にならない．(理由は参考資料のp97) そこで，分散の逆数$\lambda=1/\sigma^2$を精度パラメータとよび，精度パラメータの共役事前分布として，ガンマ分布$\mathcal{G}(\lambda|\kappa,\xi)$を用いる．
$$\mathcal{G}(\lambda|\kappa,\xi)=\frac{\xi^\kappa}{\Gamma(\kappa)}\lambda^{\kappa-1}\exp(-\xi\lambda)$$
$\kappa$は形状パラメータ，$\xi$はレートパラメータと呼ばれる．
ガンマ分布の余談 $\kappa=1$のガンマ分布は指数分布と一致する．
$$\mathcal{G}(\lambda|1,\xi)=\frac{\xi}{\Gamma(1)}\exp(-\xi\lambda)=\xi\exp(-\xi\lambda)$$
$\xi=\frac{1}{2}$に設定し$\nu=2\kappa$で定義されるパラメータで表したものは$\chi^2$分布と呼ばれる．
$$\chi^2(\lambda|\nu)=\mathcal{G}(\lambda|\frac{\nu}{2},\frac{1}{2})$$
正規-ガンマ分布 正規分布$\mathcal{N}(\mu,\lambda^{-1})$のパラメーターについて平均$\mu$は正規分布，精度$\lambda$についてはガンマ分布が事前分布として使えることを述べた． 今回は，$\mu$と$\lambda$を同時に求めることを考える． $\mu$と$\lambda$の同時分布を正規-ガンマ分布$\mathcal{NG}$とよぶ．
$$\mathcal{NG}(\mu,\lambda|\psi,\beta,\kappa,\xi)=\mathcal{N}(\mu|\psi,(\beta \lambda)^{-1}\mathcal{G}(\lambda|\kappa,\xi)$$
一般的な確率分布のパラメータとその共益事前分布 参考  手塚 太郎，&amp;quot;しくみがわかるベイズ統計と機械学習&amp;quot;  </description>
    </item>
    
    <item>
      <title>二項分布とその仲間たち</title>
      <link>https://yuhi-sa.github.io/posts/202103bayes/6/</link>
      <pubDate>Tue, 16 Mar 2021 14:00:23 +0900</pubDate>
      
      <guid>https://yuhi-sa.github.io/posts/202103bayes/6/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ベイズ推定</title>
      <link>https://yuhi-sa.github.io/posts/202103bayes/5/</link>
      <pubDate>Tue, 16 Mar 2021 13:00:23 +0900</pubDate>
      
      <guid>https://yuhi-sa.github.io/posts/202103bayes/5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>正規分布における最尤推定</title>
      <link>https://yuhi-sa.github.io/posts/202103bayes/4/</link>
      <pubDate>Tue, 16 Mar 2021 13:00:23 +0900</pubDate>
      
      <guid>https://yuhi-sa.github.io/posts/202103bayes/4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>正規分布(ガウス分布)</title>
      <link>https://yuhi-sa.github.io/posts/202103bayes/3/</link>
      <pubDate>Mon, 15 Mar 2021 13:00:23 +0900</pubDate>
      
      <guid>https://yuhi-sa.github.io/posts/202103bayes/3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>確率の基礎</title>
      <link>https://yuhi-sa.github.io/posts/202103bayes/2/</link>
      <pubDate>Mon, 15 Mar 2021 13:00:23 +0900</pubDate>
      
      <guid>https://yuhi-sa.github.io/posts/202103bayes/2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>統計学と機械学習の用語</title>
      <link>https://yuhi-sa.github.io/posts/202103bayes/1/</link>
      <pubDate>Mon, 15 Mar 2021 13:00:23 +0900</pubDate>
      
      <guid>https://yuhi-sa.github.io/posts/202103bayes/1/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
