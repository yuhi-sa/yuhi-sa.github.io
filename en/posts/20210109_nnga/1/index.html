<!doctype html><html lang=en dir=ltr data-theme=light><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#e74c3c"><meta name=format-detection content="telephone=no"><meta name=robots content="index,follow"><meta name=description content="A Python implementation of a genetic algorithm that optimizes neural network weights through selection, crossover, and mutation operations."><meta name=author content="yuhi-sa"><link rel=canonical href=https://yuhi-sa.github.io/en/posts/20210109_nnga/1/><meta property="og:type" content="article"><meta property="og:title" content="Training Neural Networks with Genetic Algorithms in Python"><meta property="og:description" content="A Python implementation of a genetic algorithm that optimizes neural network weights through selection, crossover, and mutation operations."><meta property="og:url" content="https://yuhi-sa.github.io/en/posts/20210109_nnga/1/"><meta property="og:site_name" content="tomato blog"><meta property="og:locale" content="en"><meta property="og:image" content="https://yuhi-sa.github.io/ogp.jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="article:published_time" content="2021-01-09T15:17:23+09:00"><meta property="article:modified_time" content="2026-02-14T01:34:22+09:00"><meta property="article:tag" content="Swarm Intelligence"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Python"><meta property="article:section" content="posts"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Training Neural Networks with Genetic Algorithms in Python"><meta name=twitter:description content="A Python implementation of a genetic algorithm that optimizes neural network weights through selection, crossover, and mutation operations."><meta name=twitter:image content="https://yuhi-sa.github.io/ogp.jpeg"><title>Training Neural Networks with Genetic Algorithms in Python | tomato blog</title><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><link rel=preconnect href=https://pagead2.googlesyndication.com crossorigin><link rel=dns-prefetch href=https://pagead2.googlesyndication.com><link rel=icon href=https://yuhi-sa.github.io/favicon.ico><link rel=alternate hreflang=ja href=https://yuhi-sa.github.io/posts/20210109_nnga/1/><link rel=alternate hreflang=en href=https://yuhi-sa.github.io/en/posts/20210109_nnga/1/><link rel=alternate hreflang=x-default href=https://yuhi-sa.github.io/en/posts/20210109_nnga/1/><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Training Neural Networks with Genetic Algorithms in Python","description":"A Python implementation of a genetic algorithm that optimizes neural network weights through selection, crossover, and mutation operations.","author":{"@type":"Person","name":"yuhi-sa","url":"https:\/\/yuhi-sa.github.io\/"},"publisher":{"@type":"Organization","name":"tomato blog","logo":{"@type":"ImageObject","url":"https:\/\/yuhi-sa.github.io\/ogp.jpeg"},"url":"https:\/\/yuhi-sa.github.io\/"},"datePublished":"2021-01-09T15:17:23\u002b09:00","dateModified":"2026-02-14T01:34:22\u002b09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/yuhi-sa.github.io\/en\/posts\/20210109_nnga\/1\/"},"url":"https:\/\/yuhi-sa.github.io\/en\/posts\/20210109_nnga\/1\/","wordCount":996,"keywords":["Swarm Intelligence","Machine Learning","Python"],"articleSection":"Posts","inLanguage":"en","timeRequired":"PT5M"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"tomato blog","item":"https:\/\/yuhi-sa.github.io\/en\/"},{"@type":"ListItem","position":2,"name":"Posts","item":"https:\/\/yuhi-sa.github.io\/en\/posts\/"},{"@type":"ListItem","position":3,"name":"Training Neural Networks with Genetic Algorithms in Python"}]}</script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw==" crossorigin=anonymous referrerpolicy=no-referrer><link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH crossorigin=anonymous><link rel=stylesheet href=/css/variables.min.72a177faa7b12de55dcc39c4ab6b6392116718d5e2735dab0214511354ecb973.css integrity="sha256-cqF3+qexLeVdzDnEq2tjkhFnGNXic12rAhRRE1TsuXM=" crossorigin=anonymous><link rel=stylesheet href=/css/main.min.403a82b29e94ee6e7a39204b5082cdf8b4966cfb44115390da7d8867a5006acd.css integrity="sha256-QDqCsp6U7m56OSBLUILN+LSWbPtEEVOQ2n2IZ6UAas0=" crossorigin=anonymous><link rel=stylesheet href=/css/syntax.min.e379066489e20d5433ca35ac1f468fd9e8859705a62d77a79bb7379ac3613848.css integrity="sha256-43kGZIniDVQzyjWsH0aP2eiFlwWmLXenm7c3msNhOEg=" crossorigin=anonymous><style>body{font-family:-apple-system,BlinkMacSystemFont,inter,segoe ui,Roboto,sans-serif;line-height:1.5;color:#000;background:#fff}[data-theme=dark] body{color:#fff;background:#000}.container{max-width:768px;margin:0 auto;padding:0 1rem}</style><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js integrity=sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz crossorigin=anonymous defer></script><script src=/js/dark-mode.min.3e457dc8346f064bee795e6f9b73e1516dcd059e750c521fe4b445f9ea9a7821.js integrity="sha256-PkV9yDRvBkvueV5vm3PhUW3NBZ51DFIf5LRF+eqaeCE=" defer></script><script>window.addEventListener("load",function(){const e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3",document.head.appendChild(e),e.onload=function(){window.dataLayer=window.dataLayer||[];function e(){dataLayer.push(arguments)}e("js",new Date),e("config","G-LN6QP6VVM3")}})</script><script>window.MathJax={tex:{inlineMath:[["\\(","\\)"]],displayMath:[["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js id=mathjax-script async></script></head><body itemscope itemtype=https://schema.org/WebPage class=theme-tomatohugo><a href=#main-content class="skip-link sr-only sr-only-focusable" aria-label="Skip to main content">Skip to main content</a><header role=banner class=site-header><nav class="navbar navbar-expand-lg navbar-light bg-light" role=navigation aria-label="Main navigation"><div class=container><a class=navbar-brand href=https://yuhi-sa.github.io/ aria-label="Return to tomato blog homepage">tomato blog
</a><button class="navbar-toggler d-lg-none" type=button data-bs-toggle=collapse data-bs-target=#navbarNav aria-controls=navbarNav aria-expanded=false aria-label="Toggle navigation menu">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarNav><ul class="navbar-nav ms-auto" role=menubar><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/en/ role=menuitem aria-label="Navigate to Blog">Blog</a></li><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/en/tags/ role=menuitem aria-label="Navigate to Tags">Tags</a></li><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/en/posts/about/ role=menuitem aria-label="Navigate to About">About</a></li><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/en/posts/privacy_policy/ role=menuitem aria-label="Navigate to Privacy policy">Privacy policy</a></li><li class=nav-item role=none><button id=darkModeToggle class="nav-link btn btn-link border-0" type=button role=menuitem aria-label="Toggle dark mode" title="Switch between light and dark themes">
<i class="fas fa-moon" id=darkModeIcon aria-hidden=true></i>
<span class="d-lg-none ms-2">ダークモード</span></button></li></ul></div></div></nav><script data-ad-client=ca-pub-9558545098866170 async crossorigin=anonymous src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></header><main id=main-content role=main class=site-main aria-label="Main content"><div class="container mt-4"><div class="row justify-content-center"><div class=col-lg-8><article itemscope itemtype=https://schema.org/Article><header class=article-header><h1 itemprop=headline>Training Neural Networks with Genetic Algorithms in Python</h1><p class="lead article-description" itemprop=description>A Python implementation of a genetic algorithm that optimizes neural network weights through selection, crossover, and mutation operations.</p><div class=article-meta><time datetime=2021-01-09T15:17:23+09:00 itemprop=datePublished><i class="far fa-calendar-alt me-1" aria-hidden=true></i>
January 9, 2021
</time><time datetime=2026-02-14T01:34:22+09:00 itemprop=dateModified class=ms-3><i class="far fa-edit me-1" aria-hidden=true></i>
Updated
February 14, 2026
</time><span aria-label="Reading time" class=ms-3><i class="far fa-clock me-1" aria-hidden=true></i>
5 min read</span></div><div class=article-tags role=group aria-label="Article tags"><a href=/en/tags/swarm-intelligence/ class="badge badge-custom text-decoration-none me-1" rel=tag itemprop=keywords>Swarm Intelligence
</a><a href=/en/tags/machine-learning/ class="badge badge-custom text-decoration-none me-1" rel=tag itemprop=keywords>Machine Learning
</a><a href=/en/tags/python/ class="badge badge-custom text-decoration-none me-1" rel=tag itemprop=keywords>Python</a></div></header><div class=article-content itemprop=articleBody><h2 id=introduction>Introduction</h2><p>This article explains how to use a Genetic Algorithm (GA) to train the weights and biases of a neural network (NN) that approximates a specific function. GA is an optimization method inspired by biological evolution, and it can be effective for complex problems where gradient-based methods are difficult to apply.</p><p>The target function to learn is:</p>\[ f(x,y) = \frac{\sin(x^2) / \cos(y) + x^2 - 5y + 30}{80} \]<h2 id=genetic-algorithm-ga>Genetic Algorithm (GA)</h2><p>GA is a search algorithm that mimics the mechanisms of biological evolution, particularly the principle of &ldquo;survival of the fittest.&rdquo; It represents candidate solutions as a population of &ldquo;individuals (genes)&rdquo; and evolves them toward better solutions through repeated genetic operations.</p><h3 id=basic-ga-algorithm>Basic GA Algorithm</h3><ol><li><strong>Initialize Population</strong>: Randomly generate a population of individuals (in this case, NN weights and biases).</li><li><strong>Evaluate Fitness</strong>: Calculate the &ldquo;fitness&rdquo; of each individual, measuring how well it solves the problem. Here, lower error between NN output and training data means higher fitness.</li><li><strong>Selection (Reproduction)</strong>: Select individuals so that those with higher fitness have more opportunities to pass their genes to the next generation.</li><li><strong>Crossover</strong>: Create new individuals (offspring) by exchanging parts of the genes between selected pairs. This combines promising elements from different solutions.</li><li><strong>Mutation</strong>: With a certain probability, randomly alter parts of an individual&rsquo;s genes. This promotes escape from local optima and maintains diversity.</li><li><strong>Generational Replacement</strong>: Replace the current population with the newly generated individuals.</li><li><strong>Termination Check</strong>: Stop if the maximum number of generations is reached or a satisfactory solution is found. Otherwise, return to step 2.</li></ol><h3 id=properties-of-ga>Properties of GA</h3><ul><li><strong>Advantage</strong>: Since gradient information is not required, GA can be applied to a wide range of problems regardless of differentiability or continuity. It has global search capability and is less likely to get trapped in local optima.</li><li><strong>Challenge</strong>: The best individual&rsquo;s information can be lost through genetic operations (especially crossover). Additionally, many parameters (population size, crossover rate, mutation rate, etc.) need tuning, and convergence is not guaranteed.</li></ul><h2 id=python-implementation>Python Implementation</h2><p>A set of NN weights and biases is treated as one &ldquo;gene,&rdquo; and GA is used to optimize it.</p><h3 id=key-parameters>Key Parameters</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>math</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>random</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameter settings</span>
</span></span><span class=line><span class=cl><span class=n>GENERATIONS</span> <span class=o>=</span> <span class=mi>100</span>       <span class=c1># Number of generations</span>
</span></span><span class=line><span class=cl><span class=n>POPULATION_SIZE</span> <span class=o>=</span> <span class=mi>1000</span>  <span class=c1># Population size (number of NNs)</span>
</span></span><span class=line><span class=cl><span class=n>NUM_TEACHER_DATA</span> <span class=o>=</span> <span class=mi>1000</span> <span class=c1># Number of training data points</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># NN structure</span>
</span></span><span class=line><span class=cl><span class=n>NUM_INPUT</span> <span class=o>=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>NUM_HIDDEN</span> <span class=o>=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>NUM_OUTPUT</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># GA parameters</span>
</span></span><span class=line><span class=cl><span class=n>CROSSOVER_RATE</span> <span class=o>=</span> <span class=mf>0.8</span>    <span class=c1># Crossover rate</span>
</span></span><span class=line><span class=cl><span class=n>MUTATION_RATE</span> <span class=o>=</span> <span class=mf>0.05</span>    <span class=c1># Mutation rate</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Target function</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>target_function</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Add small value to avoid divergence when cos(y) is near 0</span>
</span></span><span class=line><span class=cl>    <span class=n>cos_y</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>abs</span><span class=p>(</span><span class=n>cos_y</span><span class=p>)</span> <span class=o>&lt;</span> <span class=mf>1e-6</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>cos_y</span> <span class=o>=</span> <span class=mf>1e-6</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=n>math</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>x</span><span class=o>*</span><span class=n>x</span><span class=p>)</span> <span class=o>/</span> <span class=n>cos_y</span> <span class=o>+</span> <span class=n>x</span><span class=o>*</span><span class=n>x</span> <span class=o>-</span> <span class=mi>5</span><span class=o>*</span><span class=n>y</span> <span class=o>+</span> <span class=mi>30</span><span class=p>)</span> <span class=o>/</span> <span class=mi>80</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Activation function</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>sigmoid</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mf>1.0</span> <span class=o>/</span> <span class=p>(</span><span class=mf>1.0</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>x</span><span class=p>))</span>
</span></span></code></pre></div><h3 id=neural-network-class>Neural Network Class</h3><p>Defines the NN corresponding to each individual.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>NeuralNetwork</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Randomly initialize weights and biases</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>w_ih</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=p>(</span><span class=n>NUM_INPUT</span><span class=p>,</span> <span class=n>NUM_HIDDEN</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>b_h</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>NUM_HIDDEN</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>w_ho</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=p>(</span><span class=n>NUM_HIDDEN</span><span class=p>,</span> <span class=n>NUM_OUTPUT</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>b_o</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>NUM_OUTPUT</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fitness</span> <span class=o>=</span> <span class=mf>0.0</span> <span class=c1># Fitness</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Forward propagation</span>
</span></span><span class=line><span class=cl>        <span class=n>hidden_layer_input</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>w_ih</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>b_h</span>
</span></span><span class=line><span class=cl>        <span class=n>hidden_layer_output</span> <span class=o>=</span> <span class=n>sigmoid</span><span class=p>(</span><span class=n>hidden_layer_input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output_layer_input</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>hidden_layer_output</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>w_ho</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>b_o</span>
</span></span><span class=line><span class=cl>        <span class=c1># Output layer uses identity activation</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output_layer_input</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>calculate_fitness</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>teacher_inputs</span><span class=p>,</span> <span class=n>teacher_outputs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Calculate mean squared error over all training data</span>
</span></span><span class=line><span class=cl>        <span class=n>error</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>teacher_inputs</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>            <span class=n>prediction</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>teacher_inputs</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=n>error</span> <span class=o>+=</span> <span class=p>(</span><span class=n>prediction</span> <span class=o>-</span> <span class=n>teacher_outputs</span><span class=p>[</span><span class=n>i</span><span class=p>])</span> <span class=o>**</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>mean_squared_error</span> <span class=o>=</span> <span class=n>error</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>teacher_inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Define fitness so lower error = higher fitness</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fitness</span> <span class=o>=</span> <span class=mf>1.0</span> <span class=o>/</span> <span class=p>(</span><span class=n>mean_squared_error</span> <span class=o>+</span> <span class=mf>1e-9</span><span class=p>)</span> <span class=c1># Avoid division by zero</span>
</span></span></code></pre></div><h3 id=ga-class>GA Class</h3><p>Implements GA operations (selection, crossover, mutation).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>GeneticAlgorithm</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>population</span> <span class=o>=</span> <span class=p>[</span><span class=n>NeuralNetwork</span><span class=p>()</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>POPULATION_SIZE</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>run_generation</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>teacher_inputs</span><span class=p>,</span> <span class=n>teacher_outputs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 1. Calculate fitness for all individuals</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>individual</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>population</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>individual</span><span class=o>.</span><span class=n>calculate_fitness</span><span class=p>(</span><span class=n>teacher_inputs</span><span class=p>,</span> <span class=n>teacher_outputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 2. Generate new generation</span>
</span></span><span class=line><span class=cl>        <span class=n>new_population</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Elitism: Keep the best individual unchanged</span>
</span></span><span class=line><span class=cl>        <span class=n>elite</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>population</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>ind</span><span class=p>:</span> <span class=n>ind</span><span class=o>.</span><span class=n>fitness</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>new_population</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>elite</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>while</span> <span class=nb>len</span><span class=p>(</span><span class=n>new_population</span><span class=p>)</span> <span class=o>&lt;</span> <span class=n>POPULATION_SIZE</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 3. Selection (roulette wheel selection)</span>
</span></span><span class=line><span class=cl>            <span class=n>parent1</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_roulette_selection</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>parent2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_roulette_selection</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 4. Crossover</span>
</span></span><span class=line><span class=cl>            <span class=n>child1</span><span class=p>,</span> <span class=n>child2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_crossover</span><span class=p>(</span><span class=n>parent1</span><span class=p>,</span> <span class=n>parent2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 5. Mutation</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_mutate</span><span class=p>(</span><span class=n>child1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_mutate</span><span class=p>(</span><span class=n>child2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>new_population</span><span class=o>.</span><span class=n>extend</span><span class=p>([</span><span class=n>child1</span><span class=p>,</span> <span class=n>child2</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>population</span> <span class=o>=</span> <span class=n>new_population</span><span class=p>[:</span><span class=n>POPULATION_SIZE</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_roulette_selection</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>total_fitness</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>ind</span><span class=o>.</span><span class=n>fitness</span> <span class=k>for</span> <span class=n>ind</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>population</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>pick</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>total_fitness</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>current</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>individual</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>population</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>current</span> <span class=o>+=</span> <span class=n>individual</span><span class=o>.</span><span class=n>fitness</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>current</span> <span class=o>&gt;</span> <span class=n>pick</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>return</span> <span class=n>individual</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>population</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_crossover</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>parent1</span><span class=p>,</span> <span class=n>parent2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>child1</span> <span class=o>=</span> <span class=n>NeuralNetwork</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>child2</span> <span class=o>=</span> <span class=n>NeuralNetwork</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>random</span><span class=o>.</span><span class=n>random</span><span class=p>()</span> <span class=o>&lt;</span> <span class=n>CROSSOVER_RATE</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># Randomly swap parameter sets (uniform crossover, simplified)</span>
</span></span><span class=line><span class=cl>            <span class=n>child1</span><span class=o>.</span><span class=n>w_ih</span><span class=p>,</span> <span class=n>child2</span><span class=o>.</span><span class=n>w_ih</span> <span class=o>=</span> <span class=p>(</span><span class=n>parent1</span><span class=o>.</span><span class=n>w_ih</span><span class=p>,</span> <span class=n>parent2</span><span class=o>.</span><span class=n>w_ih</span><span class=p>)</span> <span class=k>if</span> <span class=n>random</span><span class=o>.</span><span class=n>random</span><span class=p>()</span> <span class=o>&lt;</span> <span class=mf>0.5</span> <span class=k>else</span> <span class=p>(</span><span class=n>parent2</span><span class=o>.</span><span class=n>w_ih</span><span class=p>,</span> <span class=n>parent1</span><span class=o>.</span><span class=n>w_ih</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>child1</span><span class=o>.</span><span class=n>b_h</span><span class=p>,</span> <span class=n>child2</span><span class=o>.</span><span class=n>b_h</span> <span class=o>=</span> <span class=p>(</span><span class=n>parent1</span><span class=o>.</span><span class=n>b_h</span><span class=p>,</span> <span class=n>parent2</span><span class=o>.</span><span class=n>b_h</span><span class=p>)</span> <span class=k>if</span> <span class=n>random</span><span class=o>.</span><span class=n>random</span><span class=p>()</span> <span class=o>&lt;</span> <span class=mf>0.5</span> <span class=k>else</span> <span class=p>(</span><span class=n>parent2</span><span class=o>.</span><span class=n>b_h</span><span class=p>,</span> <span class=n>parent1</span><span class=o>.</span><span class=n>b_h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>child1</span><span class=o>.</span><span class=n>w_ho</span><span class=p>,</span> <span class=n>child2</span><span class=o>.</span><span class=n>w_ho</span> <span class=o>=</span> <span class=p>(</span><span class=n>parent1</span><span class=o>.</span><span class=n>w_ho</span><span class=p>,</span> <span class=n>parent2</span><span class=o>.</span><span class=n>w_ho</span><span class=p>)</span> <span class=k>if</span> <span class=n>random</span><span class=o>.</span><span class=n>random</span><span class=p>()</span> <span class=o>&lt;</span> <span class=mf>0.5</span> <span class=k>else</span> <span class=p>(</span><span class=n>parent2</span><span class=o>.</span><span class=n>w_ho</span><span class=p>,</span> <span class=n>parent1</span><span class=o>.</span><span class=n>w_ho</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>child1</span><span class=o>.</span><span class=n>b_o</span><span class=p>,</span> <span class=n>child2</span><span class=o>.</span><span class=n>b_o</span> <span class=o>=</span> <span class=p>(</span><span class=n>parent1</span><span class=o>.</span><span class=n>b_o</span><span class=p>,</span> <span class=n>parent2</span><span class=o>.</span><span class=n>b_o</span><span class=p>)</span> <span class=k>if</span> <span class=n>random</span><span class=o>.</span><span class=n>random</span><span class=p>()</span> <span class=o>&lt;</span> <span class=mf>0.5</span> <span class=k>else</span> <span class=p>(</span><span class=n>parent2</span><span class=o>.</span><span class=n>b_o</span><span class=p>,</span> <span class=n>parent1</span><span class=o>.</span><span class=n>b_o</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>child1</span><span class=p>,</span> <span class=n>child2</span> <span class=o>=</span> <span class=n>parent1</span><span class=p>,</span> <span class=n>parent2</span> <span class=c1># No crossover</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>child1</span><span class=p>,</span> <span class=n>child2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_mutate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>individual</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Replace each weight/bias with probability MUTATION_RATE</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>w</span> <span class=ow>in</span> <span class=p>[</span><span class=n>individual</span><span class=o>.</span><span class=n>w_ih</span><span class=p>,</span> <span class=n>individual</span><span class=o>.</span><span class=n>b_h</span><span class=p>,</span> <span class=n>individual</span><span class=o>.</span><span class=n>w_ho</span><span class=p>,</span> <span class=n>individual</span><span class=o>.</span><span class=n>b_o</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>random</span><span class=o>.</span><span class=n>random</span><span class=p>()</span> <span class=o>&lt;</span> <span class=n>MUTATION_RATE</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>w</span> <span class=o>+=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=n>w</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=main-function>Main Function</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># Generate training data</span>
</span></span><span class=line><span class=cl>    <span class=n>teacher_inputs</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=p>(</span><span class=n>NUM_TEACHER_DATA</span><span class=p>,</span> <span class=n>NUM_INPUT</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>teacher_outputs</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>target_function</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>x</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>teacher_inputs</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Generate test data</span>
</span></span><span class=line><span class=cl>    <span class=n>test_inputs</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=p>(</span><span class=n>NUM_TEACHER_DATA</span><span class=p>,</span> <span class=n>NUM_INPUT</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>test_outputs</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>target_function</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>x</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>test_inputs</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>ga</span> <span class=o>=</span> <span class=n>GeneticAlgorithm</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>elite_errors</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Training started...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>gen</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>GENERATIONS</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>ga</span><span class=o>.</span><span class=n>run_generation</span><span class=p>(</span><span class=n>teacher_inputs</span><span class=p>,</span> <span class=n>teacher_outputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Find the best individual (elite)</span>
</span></span><span class=line><span class=cl>        <span class=n>elite</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>ga</span><span class=o>.</span><span class=n>population</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>ind</span><span class=p>:</span> <span class=n>ind</span><span class=o>.</span><span class=n>fitness</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Evaluate elite on test data</span>
</span></span><span class=line><span class=cl>        <span class=n>test_error</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>test_inputs</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>            <span class=n>prediction</span> <span class=o>=</span> <span class=n>elite</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>test_inputs</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=n>test_error</span> <span class=o>+=</span> <span class=p>(</span><span class=n>prediction</span> <span class=o>-</span> <span class=n>test_outputs</span><span class=p>[</span><span class=n>i</span><span class=p>])</span> <span class=o>**</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>mean_squared_error</span> <span class=o>=</span> <span class=n>test_error</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>test_inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>elite_errors</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>gen</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=mi>10</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Generation: </span><span class=si>{</span><span class=n>gen</span> <span class=o>+</span> <span class=mi>1</span><span class=si>}</span><span class=s2>, Test Error (MSE): </span><span class=si>{</span><span class=n>mean_squared_error</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Plot results</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>elite_errors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&#34;Elite Individual&#39;s Error on Test Data&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&#34;Generation&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&#34;Mean Squared Error&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s2>&#34;ga_nn_learning_curve.png&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>main</span><span class=p>()</span>
</span></span></code></pre></div><h2 id=experimental-results>Experimental Results</h2><p>The elite individual (highest fitness) from each generation was evaluated on test data, and the mean squared error was plotted. As generations progress, the error decreases, confirming that the NN is learning the function.</p><p><img src=/posts/20210109_nnga/fig1.png alt="Learning Results"></p></div><div class="ad-slot in-content my-3"><ins class=adsbygoogle style=display:block;text-align:center data-ad-layout=in-article data-ad-format=fluid data-ad-client=ca-pub-9558545098866170></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><footer class=article-footer></footer><meta itemprop=wordCount content="996"><meta itemprop=url content="https://yuhi-sa.github.io/en/posts/20210109_nnga/1/"></article><nav class="post-nav mt-5" aria-label="Post navigation"><a href=/en/posts/20210108_bayes/1/ class="post-nav__item post-nav__item--prev"><span class="post-nav__label text-muted"><i class="fas fa-arrow-left me-1" aria-hidden=true></i>前の記事
</span><span class=post-nav__title>Bayesian Linear Regression: From Least Squares to Bayesian Estimation</span>
</a><a href=/en/posts/20210125_ut/1/ class="post-nav__item post-nav__item--next"><span class="post-nav__label text-muted">次の記事<i class="fas fa-arrow-right ms-1" aria-hidden=true></i>
</span><span class=post-nav__title>Unscented Transformation: Algorithm and Python Implementation</span></a></nav><section class="related-posts mt-5" aria-label="Related posts"><h2 class=related-posts__title>関連記事</h2><div class=related-posts__grid><article class=related-posts__item><h3 class=related-posts__item-title><a href=/en/posts/20260223_bayesian_optimization/1/>Bayesian Optimization: Fundamentals and Python Implementation</a></h3><div class=card-meta><time datetime=2026-02-23>February 23, 2026</time></div></article><article class=related-posts__item><h3 class=related-posts__item-title><a href=/en/posts/20260215_mppi/1/>MPPI (Model Predictive Path Integral): A Unified View with the Cross-Entropy Method</a></h3><div class=card-meta><time datetime=2026-02-15>February 15, 2026</time></div></article><article class=related-posts__item><h3 class=related-posts__item-title><a href=/en/posts/20260215_ckf/1/>Cubature Kalman Filter (CKF): Theory and Python Implementation</a></h3><div class=card-meta><time datetime=2026-02-15>February 15, 2026</time></div></article></div></section><nav class="article-navigation mt-4" aria-label="Article navigation"><a href=/en/posts/ class="btn btn-outline-secondary btn-sm mb-3"><i class="fas fa-arrow-left me-1" aria-hidden=true></i>
Back to posts</a><nav aria-label="Breadcrumb navigation" class=breadcrumb-nav role=navigation><ol class=breadcrumb itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumb-item itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=/en/ itemprop=item aria-label="Navigate to homepage"><i class="fas fa-home" aria-hidden=true></i>
<span itemprop=name>tomato blog</span>
</a><meta itemprop=position content="1"></li><li class=breadcrumb-item itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=https://yuhi-sa.github.io/en/ itemprop=item aria-label="Navigate to tomato blog"><span itemprop=name>tomato blog</span>
</a><meta itemprop=position content="2"></li><li class=breadcrumb-item itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=https://yuhi-sa.github.io/en/posts/ itemprop=item aria-label="Navigate to Posts"><span itemprop=name>Posts</span>
</a><meta itemprop=position content="3"></li><li class="breadcrumb-item active" aria-current=page itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><span itemprop=name>Training Neural Networks with Genetic Algorithms in Python</span>
<meta itemprop=position content="4"></li></ol></nav></nav></div></div></div></main><footer role=contentinfo class=site-footer><div class="container pt-4 pb-3" style="border-top:2px solid var(--accent,#e54d2e)"><div class="row justify-content-center"><div class="col-md-8 text-center"><p class="copyright-text text-muted mb-2">&copy; 2026 yuhi-sa. All rights reserved.</p><p class="theme-attribution text-muted small mt-2 mb-0">Powered by
<a href=https://gohugo.io/ target=_blank rel=noopener class=text-decoration-none>Hugo</a>
with
<a href=https://github.com/yuhi-sa/tomatohugo target=_blank rel=noopener class=text-decoration-none>TomatoHugo</a></p></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js integrity=sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz crossorigin=anonymous defer></script><script src=/js/dark-mode.min.3e457dc8346f064bee795e6f9b73e1516dcd059e750c521fe4b445f9ea9a7821.js integrity="sha256-PkV9yDRvBkvueV5vm3PhUW3NBZ51DFIf5LRF+eqaeCE=" defer></script><script>window.addEventListener("load",function(){const e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3",document.head.appendChild(e),e.onload=function(){window.dataLayer=window.dataLayer||[];function e(){dataLayer.push(arguments)}e("js",new Date),e("config","G-LN6QP6VVM3")}})</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebPage","name":"Training Neural Networks with Genetic Algorithms in Python","url":"https:\/\/yuhi-sa.github.io\/en\/posts\/20210109_nnga\/1\/","description":"A Python implementation of a genetic algorithm that optimizes neural network weights through selection, crossover, and mutation operations.","inLanguage":"en","isPartOf":{"@type":"WebSite","name":"tomato blog","url":"https:\/\/yuhi-sa.github.io\/"}}</script></body></html>