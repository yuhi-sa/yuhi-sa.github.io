<!doctype html><html lang=en dir=ltr data-theme=light><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=format-detection content="telephone=no"><meta name=robots content="index,follow"><meta name=description content="勉強したことなどをメモしています"><link rel=canonical href=https://yuhi-sa.github.io/en/posts/20211102_op3/1/><meta property="og:type" content="article"><meta property="og:title" content="Code description of ROS package to make op3 acquire walking using reinforcement learning"><meta property="og:description" content="勉強したことなどをメモしています"><meta property="og:url" content="https://yuhi-sa.github.io/en/posts/20211102_op3/1/"><meta property="og:site_name" content="tomato blog"><meta property="og:locale" content="en"><meta property="og:image" content="https://yuhi-sa.github.io/ogp.jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="article:published_time" content="2021-11-02T10:17:23+09:00"><meta property="article:modified_time" content="2025-07-23T20:43:29+09:00"><meta property="article:tag" content="Others"><meta property="article:section" content="posts"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Code description of ROS package to make op3 acquire walking using reinforcement learning"><meta name=twitter:description content="勉強したことなどをメモしています"><meta name=twitter:image content="https://yuhi-sa.github.io/ogp.jpeg"><title>Code description of ROS package to make op3 acquire walking using reinforcement learning | tomato blog</title><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Code description of ROS package to make op3 acquire walking using reinforcement learning","description":"","author":{"@type":"Person","name":""},"publisher":{"@type":"Organization","name":"tomato blog","url":"https:\/\/yuhi-sa.github.io\/"},"datePublished":"2021-11-02T10:17:23\u002b09:00","dateModified":"2025-07-23T20:43:29\u002b09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/yuhi-sa.github.io\/en\/posts\/20211102_op3\/1\/"},"url":"https:\/\/yuhi-sa.github.io\/en\/posts\/20211102_op3\/1\/","wordCount":394,"keywords":["Others"],"articleSection":"Posts","inLanguage":"en","timeRequired":"PT2M"}</script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw==" crossorigin=anonymous referrerpolicy=no-referrer><link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH crossorigin=anonymous><link rel=stylesheet href=/css/variables.min.963335e1959a83c16c6f09e75be26e42b746222835a882f77a89d68f9883aafe.css integrity="sha256-ljM14ZWag8FsbwnnW+JuQrdGIig1qIL3eonWj5iDqv4=" crossorigin=anonymous><link rel=stylesheet href=/css/main.min.65d091264255d75817988ed1dce4adcef2482557713854f8aaa3dde137672915.css integrity="sha256-ZdCRJkJV11gXmI7R3OStzvJIJVdxOFT4qqPd4TdnKRU=" crossorigin=anonymous><link rel=stylesheet href=/css/syntax.min.20b142b4e47bd9042b2d9fffa65797c455e75d76c4797957d567b04a03fd8b0c.css integrity="sha256-ILFCtOR72QQrLZ//pleXxFXnXXbEeXlX1WewSgP9iww=" crossorigin=anonymous><style>body{font-family:-apple-system,BlinkMacSystemFont,inter,segoe ui,Roboto,sans-serif;line-height:1.5;color:#000;background:#fff}[data-theme=dark] body{color:#fff;background:#000}.container{max-width:768px;margin:0 auto;padding:0 1rem}</style><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js integrity=sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz crossorigin=anonymous defer></script><script src=/js/dark-mode.min.3e457dc8346f064bee795e6f9b73e1516dcd059e750c521fe4b445f9ea9a7821.js integrity="sha256-PkV9yDRvBkvueV5vm3PhUW3NBZ51DFIf5LRF+eqaeCE=" defer></script><script>window.addEventListener("load",function(){const e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3",document.head.appendChild(e),e.onload=function(){window.dataLayer=window.dataLayer||[];function e(){dataLayer.push(arguments)}e("js",new Date),e("config","G-LN6QP6VVM3")}})</script><script>"serviceWorker"in navigator&&window.addEventListener("load",function(){navigator.serviceWorker.register("/sw.js").then(function(e){console.log("SW registered: ",e)}).catch(function(e){console.log("SW registration failed: ",e)})})</script></head><body itemscope itemtype=https://schema.org/WebPage class=theme-tomatohugo><a href=#main-content class="skip-link sr-only sr-only-focusable" aria-label="Skip to main content">Skip to main content</a><header role=banner class=site-header><nav class="navbar navbar-expand-lg navbar-light bg-light" role=navigation aria-label="Main navigation"><div class=container><a class=navbar-brand href=https://yuhi-sa.github.io/ aria-label="Return to tomato blog homepage">tomato blog
</a><button class="navbar-toggler d-lg-none" type=button data-bs-toggle=collapse data-bs-target=#navbarNav aria-controls=navbarNav aria-expanded=false aria-label="Toggle navigation menu">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarNav><ul class="navbar-nav ms-auto" role=menubar><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/ role=menuitem aria-label="Navigate to Blog">Blog</a></li><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/tags/ role=menuitem aria-label="Navigate to Tags">Tags</a></li><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/posts/about/ role=menuitem aria-label="Navigate to About">About</a></li><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/posts/privacy_policy/ role=menuitem aria-label="Navigate to Privacy policy">Privacy policy</a></li><li class=nav-item role=none><button id=darkModeToggle class="nav-link btn btn-link border-0" type=button role=menuitem aria-label="Toggle dark mode" title="Switch between light and dark themes">
<i class="fas fa-moon" id=darkModeIcon aria-hidden=true></i>
<span class="d-lg-none ms-2">ダークモード</span></button></li></ul></div></div></nav><script async src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-LN6QP6VVM3")</script><script data-ad-client=ca-pub-9558545098866170 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></header><main id=main-content role=main class=site-main aria-label="Main content"><div class="container mt-4"><div class="row justify-content-center"><div class=col-lg-8><article itemscope itemtype=https://schema.org/Article><header class=article-header><h1 itemprop=headline>Code description of ROS package to make op3 acquire walking using reinforcement learning</h1><div class=article-meta><time datetime=2021-11-02T10:17:23+09:00 itemprop=datePublished><i class="far fa-calendar-alt me-1" aria-hidden=true></i>
November 2, 2021
</time><time datetime=2025-07-23T20:43:29+09:00 itemprop=dateModified class=ms-3><i class="far fa-edit me-1" aria-hidden=true></i>
Updated July 23, 2025
</time><span aria-label="Reading time" class=ms-3><i class="far fa-clock me-1" aria-hidden=true></i>
2 min read</span></div><div class=article-tags role=group aria-label="Article tags"><a href=/en/tags/others/ class="badge badge-custom text-decoration-none me-1" rel=tag itemprop=keywords>Others</a></div></header><div class=article-content itemprop=articleBody><h2 id=introduction>Introduction</h2><p>This article explains the code of a ROS (Robot Operating System) package that enables the ROBOTIS OP3 humanoid robot to acquire walking locomotion using reinforcement learning within the Gazebo simulation environment.</p><ul><li>Related repository: <a href=https://github.com/yuhi-sa/op3_walk>op3_walk</a></li></ul><h2 id=result-video>Result Video</h2><p>The learned walking motion of OP3 can be seen in the following video:</p><ul><li><a href=https://github.com/yuhi-sa/op3_walk/blob/main/docs/op3_controller_demo.mp4>op3_controller_demo</a></li></ul><h2 id=method-description>Method Description</h2><p>This project utilizes <strong>Deep Q-Network (DQN)</strong>. DQN combines Q-learning with deep learning, approximating the action-value function with a neural network.</p><p>The action-value function $Q(s_t, a_t)$ is defined as a three-layer neural network and is updated based on the following Q-learning update rule:</p><p>$ Q(s_t, a_t) \leftarrow Q(s_t, a_t) + \eta (R_{t+1} + \gamma \max_{a&rsquo;} Q(s_{t+1}, a&rsquo;) - Q(s_t, a_t)) $</p><p>Here, $\eta$ is the learning rate, $R_{t+1}$ is the immediate reward, and $\gamma$ is the discount factor.</p><p>The neural network is updated using backpropagation with the following loss function $L$:</p><p>$ L = \mathbb{E}[(R_{t+1} + \gamma \max_{a&rsquo;} Q(s_{t+1}, a&rsquo;) - Q(s_t, a_t))^2] $</p><h2 id=program-structure>Program Structure</h2><p>This ROS package primarily consists of the following Python scripts:</p><h3 id=1-functionpy-and-motionpy>1. <code>function.py</code> and <code>motion.py</code></h3><ul><li><a href=https://github.com/yuhi-sa/op3_walk/blob/main/scripts/function.py><code>function.py</code></a>: Contains the basic definitions for the reinforcement learning agent.<ul><li><code>Agent</code> class: Encapsulates a <code>Brain</code> class that defines the neural network.</li><li><code>ReplayMemory</code> class: Stores experiences (actions and states) collected by the agent from the environment. The <code>Brain</code> samples from this memory for loss calculation and neural network updates.</li><li>Actions are discretized, and selection is made based on the <code>epsilon-greedy</code> method.</li></ul></li><li><a href=https://github.com/yuhi-sa/op3_walk/blob/main/scripts/motion.py><code>motion.py</code></a>: Defines the specific discrete actions of the robot (e.g., target angles for each joint).</li></ul><p>These scripts are based on the code from the following book:</p><ul><li><a href=https://github.com/YutaroOgawa/Deep-Reinforcement-Learning-Book>Deep-Reinforcement-Learning-Book</a></li></ul><h3 id=2-learningpy>2. <code>learning.py</code></h3><ul><li><a href=https://github.com/yuhi-sa/op3_walk/blob/main/scripts/learning.py><code>learning.py</code></a>: Inherits from the <code>Agent</code> class defined in <code>function.py</code> and operates as a ROS node.<ul><li>Subscribes to robot states as ROS topics from <code>controller.py</code>.</li><li>Calculates actions based on the subscribed states and publishes these actions as ROS topics.</li><li>Uses PyTorch for neural network definition, requiring Python 3 for execution.</li></ul></li></ul><h3 id=3-controllerpy>3. <code>controller.py</code></h3><ul><li><a href=https://github.com/yuhi-sa/op3_walk/blob/main/scripts/controller.py><code>controller.py</code></a>: Subscribes to actions published by <code>learning.py</code> as ROS topics and controls the ROBOTIS OP3 in the Gazebo simulation.<ul><li>Publishes the robot&rsquo;s current state (joint angles, center of mass position, etc.) as ROS topics.</li><li>Due to dependencies of the OP3 ROS package, this script needs to be run in Python 2.</li></ul></li></ul><h2 id=learning-curve>Learning Curve</h2><p>Graph showing the change in walking distance as learning progresses. It can be observed that the walking distance increases with generations, indicating that the agent is learning efficient locomotion.</p><p><img src="https://github.com/yuhi-sa/op3_walk/blob/main/docs/learning.png?raw=true" alt="Walking Distance"></p></div><footer class=article-footer></footer><meta itemprop=wordCount content="394"><meta itemprop=url content="https://yuhi-sa.github.io/en/posts/20211102_op3/1/"></article><nav class="article-navigation mt-5" aria-label="Article navigation"><nav aria-label="Breadcrumb navigation" class=breadcrumb-nav role=navigation><ol class=breadcrumb itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumb-item itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=/en/ itemprop=item aria-label="Navigate to homepage"><i class="fas fa-home" aria-hidden=true></i>
<span itemprop=name>tomato blog</span>
</a><meta itemprop=position content="1"></li><li class=breadcrumb-item itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=https://yuhi-sa.github.io/en/ itemprop=item aria-label="Navigate to tomato blog"><span itemprop=name>tomato blog</span>
</a><meta itemprop=position content="2"></li><li class=breadcrumb-item itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=https://yuhi-sa.github.io/en/posts/ itemprop=item aria-label="Navigate to Posts"><span itemprop=name>Posts</span>
</a><meta itemprop=position content="3"></li><li class="breadcrumb-item active" aria-current=page itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><span itemprop=name>Code description of ROS package to make op3 acquire walking using reinforcement learning</span>
<meta itemprop=position content="4"></li></ol></nav><div class=terms-wrapper role=region aria-label=Tags><h6 class=terms-label id=terms-tags>Tags:</h6><ul class=terms-list role=list aria-labelledby=terms-tags aria-describedby=terms-count-tags><li class=terms-item role=listitem><a href=/en/tags/others/ class="terms-link badge badge-custom text-decoration-none" rel=tag aria-label="View all posts tagged with Others" title="Others (4 posts)">Others</a></li></ul><span id=terms-count-tags class=sr-only>1 tags total</span></div></nav></div></div></div></main><footer role=contentinfo class=site-footer><div class="container py-5"><div class="row justify-content-center"><div class="col-md-8 text-center"><p class="copyright-text text-muted mb-2">&copy; 2025
tomato blog.
All rights reserved.</p><p class="theme-attribution text-muted small mt-2 mb-0">Powered by
<a href=https://gohugo.io/ target=_blank rel=noopener class=text-decoration-none>Hugo</a>
with
<a href=https://github.com/yuhi-sa/tomatohugo target=_blank rel=noopener class=text-decoration-none>TomatoHugo</a></p></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js integrity=sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz crossorigin=anonymous defer></script><script src=/js/dark-mode.min.3e457dc8346f064bee795e6f9b73e1516dcd059e750c521fe4b445f9ea9a7821.js integrity="sha256-PkV9yDRvBkvueV5vm3PhUW3NBZ51DFIf5LRF+eqaeCE=" defer></script><script>window.addEventListener("load",function(){const e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3",document.head.appendChild(e),e.onload=function(){window.dataLayer=window.dataLayer||[];function e(){dataLayer.push(arguments)}e("js",new Date),e("config","G-LN6QP6VVM3")}})</script><script>"serviceWorker"in navigator&&window.addEventListener("load",function(){navigator.serviceWorker.register("/sw.js").then(function(e){console.log("SW registered: ",e)}).catch(function(e){console.log("SW registration failed: ",e)})})</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebPage","name":"Code description of ROS package to make op3 acquire walking using reinforcement learning","url":"https:\/\/yuhi-sa.github.io\/en\/posts\/20211102_op3\/1\/","description":"勉強したことなどをメモしています","inLanguage":"en","isPartOf":{"@type":"WebSite","name":"tomato blog","url":"https:\/\/yuhi-sa.github.io\/"}}</script></body></html>