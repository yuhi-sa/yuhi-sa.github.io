<!doctype html><html lang=en dir=ltr data-theme=light><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=format-detection content="telephone=no"><meta name=robots content="
    index
  
  ,follow"><meta name=description content="A detailed walkthrough of maximum likelihood estimation (MLE) using the normal distribution, deriving the MLE for mean and variance step by step."><link rel=canonical href=https://yuhi-sa.github.io/en/posts/20210317_bayes/4/><meta property="og:type" content="
    article
  "><meta property="og:title" content="
    Maximum Likelihood Estimation for the Normal Distribution
  "><meta property="og:description" content="A detailed walkthrough of maximum likelihood estimation (MLE) using the normal distribution, deriving the MLE for mean and variance step by step."><meta property="og:url" content="https://yuhi-sa.github.io/en/posts/20210317_bayes/4/"><meta property="og:site_name" content="tomato blog"><meta property="og:locale" content="en"><meta property="og:image" content="https://yuhi-sa.github.io/ogp.jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="article:published_time" content="2021-03-16T13:00:23+09:00"><meta property="article:modified_time" content="2026-02-14T01:34:22+09:00"><meta property="article:tag" content="Statistics"><meta property="article:tag" content="Machine Learning"><meta property="article:section" content="posts"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="
    Maximum Likelihood Estimation for the Normal Distribution
  "><meta name=twitter:description content="A detailed walkthrough of maximum likelihood estimation (MLE) using the normal distribution, deriving the MLE for mean and variance step by step."><meta name=twitter:image content="https://yuhi-sa.github.io/ogp.jpeg"><title>Maximum Likelihood Estimation for the Normal Distribution |
tomato blog</title><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><link rel=alternate hreflang=ja href=https://yuhi-sa.github.io/posts/20210317_bayes/4/><link rel=alternate hreflang=en href=https://yuhi-sa.github.io/en/posts/20210317_bayes/4/><link rel=alternate hreflang=x-default href=https://yuhi-sa.github.io/en/posts/20210317_bayes/4/><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Maximum Likelihood Estimation for the Normal Distribution","description":"A detailed walkthrough of maximum likelihood estimation (MLE) using the normal distribution, deriving the MLE for mean and variance step by step.","author":{"@type":"Person","name":""},"publisher":{"@type":"Organization","name":"tomato blog","url":"https:\/\/yuhi-sa.github.io\/"},"datePublished":"2021-03-16T13:00:23\u002b09:00","dateModified":"2026-02-14T01:34:22\u002b09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/yuhi-sa.github.io\/en\/posts\/20210317_bayes\/4\/"},"url":"https:\/\/yuhi-sa.github.io\/en\/posts\/20210317_bayes\/4\/","wordCount":515,"keywords":["Statistics","Machine Learning"],"articleSection":"Posts","inLanguage":"en","timeRequired":"PT3M"}</script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw==" crossorigin=anonymous referrerpolicy=no-referrer><link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH crossorigin=anonymous><link rel=stylesheet href=/css/variables.min.de039aff98fb649abaf5fe23d3d4981f460573d7728709826e219c496c8e5be2.css integrity="sha256-3gOa/5j7ZJq69f4j09SYH0YFc9dyhwmCbiGcSWyOW+I=" crossorigin=anonymous><link rel=stylesheet href=/css/main.min.c50b1500452fdb66f687cdcbf45a7774123c0111e1054e26db51fee604557b28.css integrity="sha256-xQsVAEUv22b2h83L9Fp3dBI8ARHhBU4m21H+5gRVeyg=" crossorigin=anonymous><link rel=stylesheet href=/css/syntax.min.e379066489e20d5433ca35ac1f468fd9e8859705a62d77a79bb7379ac3613848.css integrity="sha256-43kGZIniDVQzyjWsH0aP2eiFlwWmLXenm7c3msNhOEg=" crossorigin=anonymous><style>body{font-family:-apple-system,BlinkMacSystemFont,inter,segoe ui,Roboto,sans-serif;line-height:1.5;color:#000;background:#fff}[data-theme=dark] body{color:#fff;background:#000}.container{max-width:768px;margin:0 auto;padding:0 1rem}</style><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js integrity=sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz crossorigin=anonymous defer></script><script src=/js/dark-mode.min.3e457dc8346f064bee795e6f9b73e1516dcd059e750c521fe4b445f9ea9a7821.js integrity="sha256-PkV9yDRvBkvueV5vm3PhUW3NBZ51DFIf5LRF+eqaeCE=" defer></script><script>window.addEventListener("load",function(){const e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3",document.head.appendChild(e),e.onload=function(){window.dataLayer=window.dataLayer||[];function e(){dataLayer.push(arguments)}e("js",new Date),e("config","G-LN6QP6VVM3")}})</script><script>"serviceWorker"in navigator&&window.addEventListener("load",function(){navigator.serviceWorker.register("/sw.js").then(function(e){console.log("SW registered: ",e)}).catch(function(e){console.log("SW registration failed: ",e)})})</script><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js id=mathjax-script async></script></head><body itemscope itemtype=https://schema.org/WebPage class=theme-tomatohugo><a href=#main-content class="skip-link sr-only sr-only-focusable" aria-label="Skip to main content">Skip to main content</a><header role=banner class=site-header><nav class="navbar navbar-expand-lg navbar-light bg-light" role=navigation aria-label="Main navigation"><div class=container><a class=navbar-brand href=https://yuhi-sa.github.io/ aria-label="Return to tomato blog homepage">tomato blog
</a><button class="navbar-toggler d-lg-none" type=button data-bs-toggle=collapse data-bs-target=#navbarNav aria-controls=navbarNav aria-expanded=false aria-label="Toggle navigation menu">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarNav><ul class="navbar-nav ms-auto" role=menubar><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/en/ role=menuitem aria-label="Navigate to Blog">Blog</a></li><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/en/tags/ role=menuitem aria-label="Navigate to Tags">Tags</a></li><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/en/posts/about/ role=menuitem aria-label="Navigate to About">About</a></li><li class=nav-item role=none><a class=nav-link href=https://yuhi-sa.github.io/en/posts/privacy_policy/ role=menuitem aria-label="Navigate to Privacy policy">Privacy policy</a></li><li class=nav-item role=none><button id=darkModeToggle class="nav-link btn btn-link border-0" type=button role=menuitem aria-label="Toggle dark mode" title="Switch between light and dark themes">
<i class="fas fa-moon" id=darkModeIcon aria-hidden=true></i>
<span class="d-lg-none ms-2">ダークモード</span></button></li></ul></div></div></nav><script async src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-LN6QP6VVM3")</script><script data-ad-client=ca-pub-9558545098866170 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></header><main id=main-content role=main class=site-main aria-label="Main content"><div class="container mt-4"><div class="row justify-content-center"><div class=col-lg-8><article itemscope itemtype=https://schema.org/Article><header class=article-header><h1 itemprop=headline>Maximum Likelihood Estimation for the Normal Distribution</h1><p class="lead article-description" itemprop=description>A detailed walkthrough of maximum likelihood estimation (MLE) using the normal distribution, deriving the MLE for mean and variance step by step.</p><div class=article-meta><time datetime=2021-03-16T13:00:23+09:00 itemprop=datePublished><i class="far fa-calendar-alt me-1" aria-hidden=true></i>
March 16, 2021
</time><time datetime=2026-02-14T01:34:22+09:00 itemprop=dateModified class=ms-3><i class="far fa-edit me-1" aria-hidden=true></i>
Updated
February 14, 2026
</time><span aria-label="Reading time" class=ms-3><i class="far fa-clock me-1" aria-hidden=true></i>
3 min read</span></div><div class=article-tags role=group aria-label="Article tags"><a href=/en/tags/statistics/ class="badge badge-custom text-decoration-none me-1" rel=tag itemprop=keywords>Statistics
</a><a href=/en/tags/machine-learning/ class="badge badge-custom text-decoration-none me-1" rel=tag itemprop=keywords>Machine Learning</a></div></header><div class=article-content itemprop=articleBody><p>Maximum Likelihood Estimation (MLE) is one of the most common methods for estimating the parameters of statistical models. It was systematized by the statistician Ronald Fisher in the early 20th century.</p><h3 id=the-idea-behind-maximum-likelihood-estimation>The Idea Behind Maximum Likelihood Estimation</h3><p>MLE estimates the parameters that maximize the <strong>likelihood function</strong>. The likelihood function can be interpreted as &ldquo;<strong>the probability (or probability density) that the given data was generated by a model with specific parameters</strong>.&rdquo;</p><p>Suppose we have observed data $x = {x_1, x_2, \dots, x_n}$ that follows a probability distribution $p(x|\theta)$ with parameter $\theta$. If each observation is independently and identically distributed (i.i.d.), the likelihood function $L(\theta|x)$ is defined as the product of the probabilities of each observation.</p><p>$$ L(\theta|x) = p(x|\theta) = \prod_{i=1}^n p(x_i|\theta) $$</p><p>MLE finds the parameter $\hat{\theta}_{ML}$ that maximizes this likelihood function $L(\theta|x)$.</p><h3 id=log-likelihood-function>Log-Likelihood Function</h3><p>Since the likelihood function is a product, computations can become complex, and differentiating products is cumbersome. Therefore, it is common to maximize the <strong>log-likelihood function</strong> $\log L(\theta|x)$ instead, obtained by taking the logarithm (a monotonically increasing function). The logarithm converts products into sums, making differentiation easier.</p><p>$$ \log L(\theta|x) = \sum_{i=1}^n \log p(x_i|\theta) $$</p><p>Since the logarithm is monotonically increasing, maximizing the likelihood function is equivalent to maximizing the log-likelihood function.</p><h3 id=maximum-likelihood-estimation-for-the-normal-distribution>Maximum Likelihood Estimation for the Normal Distribution</h3><p>Here, we assume that observed data $x = {x_1, x_2, \dots, x_n}$ follows a normal distribution $\mathcal{N}(x | \mu, \sigma^2)$, and derive the MLE for its parameters: the mean $\mu$ and variance $\sigma^2$.</p><p>The probability density function of the normal distribution is:
$$ p(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right) $$</p><p>The log-likelihood function becomes:
$$ \log L(\mu, \sigma^2 | x) = -\frac{1}{2\sigma^2} \sum_{i=1}^n (x_i - \mu)^2 - \frac{n}{2} \log(2\pi\sigma^2) $$</p><h4 id=mle-of-the-mean-mu>MLE of the Mean $\mu$</h4><p>We take the partial derivative of the log-likelihood function with respect to $\mu$ and set it to zero.</p><p>$$ \frac{\partial \log L}{\partial \mu} = -\frac{1}{2\sigma^2} \sum*{i=1}^n 2(x_i - \mu)(-1) = \frac{1}{\sigma^2} \sum*{i=1}^n (x_i - \mu) $$</p><p>Setting this to zero:
$$ \sum*{i=1}^n (x_i - \mu) = 0 \implies \sum*{i=1}^n x<em>i - n\mu = 0 \implies \hat{\mu}</em>{ML} = \frac{1}{n} \sum_{i=1}^n x_i $$</p><p>Therefore, the MLE of the mean of a normal distribution equals the <strong>sample mean</strong>. This is one reason why the arithmetic mean is so widely used in statistics.</p><h4 id=mle-of-the-variance-sigma2>MLE of the Variance $\sigma^2$</h4><p>We take the partial derivative of the log-likelihood function with respect to $\sigma^2$ and set it to zero.</p><p>$$ \frac{\partial \log L}{\partial \sigma^2} = -\frac{1}{2} \sum*{i=1}^n (x_i - \mu)^2 \left(-\frac{1}{(\sigma^2)^2}\right) - \frac{n}{2} \frac{1}{\sigma^2} $$
$$ = \frac{1}{2(\sigma^2)^2} \sum*{i=1}^n (x_i - \mu)^2 - \frac{n}{2\sigma^2} $$</p><p>Setting this to zero:
$$ \frac{1}{(\sigma^2)^2} \sum*{i=1}^n (x_i - \mu)^2 = \frac{n}{\sigma^2} \implies \hat{\sigma}^2*{ML} = \frac{1}{n} \sum_{i=1}^n (x_i - \mu)^2 $$</p><p>Here, we substitute the previously derived MLE $\hat{\mu}_{ML}$ for $\mu$.</p><p>$$ \hat{\sigma}^2*{ML} = \frac{1}{n} \sum*{i=1}^n (x<em>i - \hat{\mu}</em>{ML})^2 $$</p><p>This coincides with the definition of the <strong>sample variance</strong>. Note, however, that this differs from the unbiased variance (which divides by $n-1$). The sample variance as an MLE tends to slightly underestimate the true variance.</p><h2 id=references>References</h2><ul><li>Taro Tezuka, &ldquo;Understanding Bayesian Statistics and Machine Learning,&rdquo; Kodansha (2017)</li></ul></div><footer class=article-footer></footer><meta itemprop=wordCount content="515"><meta itemprop=url content="https://yuhi-sa.github.io/en/posts/20210317_bayes/4/"></article><nav class="post-nav mt-5" aria-label="Post navigation"><a href=/en/posts/20210317_bayes/1/ class="post-nav__item post-nav__item--prev"><span class="post-nav__label text-muted"><i class="fas fa-arrow-left me-1" aria-hidden=true></i>前の記事
</span><span class=post-nav__title>Basic Terminology in Statistics and Machine Learning</span>
</a><a href=/en/posts/20210317_bayes/5/ class="post-nav__item post-nav__item--next"><span class="post-nav__label text-muted">次の記事<i class="fas fa-arrow-right ms-1" aria-hidden=true></i>
</span><span class=post-nav__title>Fundamentals of Bayesian Estimation</span></a></nav><section class="related-posts mt-5" aria-label="Related posts"><h2 class=related-posts__title>関連記事</h2><div class=related-posts__grid><article class=related-posts__item><h3 class=related-posts__item-title><a href=/en/posts/20210317_bayes/1/>Basic Terminology in Statistics and Machine Learning</a></h3><div class=card-meta><time datetime=2021-03-15>March 15, 2021</time></div></article><article class=related-posts__item><h3 class=related-posts__item-title><a href=/en/posts/20210317_bayes/2/>Fundamentals of Probability</a></h3><div class=card-meta><time datetime=2021-03-15>March 15, 2021</time></div></article><article class=related-posts__item><h3 class=related-posts__item-title><a href=/en/posts/20210317_bayes/3/>The Normal Distribution (Gaussian Distribution)</a></h3><div class=card-meta><time datetime=2021-03-15>March 15, 2021</time></div></article></div></section><nav class="article-navigation mt-4" aria-label="Article navigation"><a href=/en/posts/ class="btn btn-outline-secondary btn-sm mb-3"><i class="fas fa-arrow-left me-1" aria-hidden=true></i>
Back to posts</a><nav aria-label="Breadcrumb navigation" class=breadcrumb-nav role=navigation><ol class=breadcrumb itemscope itemtype=https://schema.org/BreadcrumbList><li class=breadcrumb-item itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=/en/ itemprop=item aria-label="Navigate to homepage"><i class="fas fa-home" aria-hidden=true></i>
<span itemprop=name>tomato blog</span>
</a><meta itemprop=position content="1"></li><li class=breadcrumb-item itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=https://yuhi-sa.github.io/en/ itemprop=item aria-label="Navigate to tomato blog"><span itemprop=name>tomato blog</span>
</a><meta itemprop=position content="2"></li><li class=breadcrumb-item itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=https://yuhi-sa.github.io/en/posts/ itemprop=item aria-label="Navigate to Posts"><span itemprop=name>Posts</span>
</a><meta itemprop=position content="3"></li><li class="breadcrumb-item active" aria-current=page itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><span itemprop=name>Maximum Likelihood Estimation for the Normal Distribution</span>
<meta itemprop=position content="4"></li></ol></nav></nav></div></div></div></main><footer role=contentinfo class=site-footer><div class="container pt-4 pb-3" style="border-top:2px solid var(--accent,#e54d2e)"><div class="row justify-content-center"><div class="col-md-8 text-center"><p class="copyright-text text-muted mb-2">&copy;
2026
tomato blog.
All rights reserved.</p><p class="theme-attribution text-muted small mt-2 mb-0">Powered by
<a href=https://gohugo.io/ target=_blank rel=noopener class=text-decoration-none>Hugo</a>
with
<a href=https://github.com/yuhi-sa/tomatohugo target=_blank rel=noopener class=text-decoration-none>TomatoHugo</a></p></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js integrity=sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz crossorigin=anonymous defer></script><script src=/js/dark-mode.min.3e457dc8346f064bee795e6f9b73e1516dcd059e750c521fe4b445f9ea9a7821.js integrity="sha256-PkV9yDRvBkvueV5vm3PhUW3NBZ51DFIf5LRF+eqaeCE=" defer></script><script>window.addEventListener("load",function(){const e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-LN6QP6VVM3",document.head.appendChild(e),e.onload=function(){window.dataLayer=window.dataLayer||[];function e(){dataLayer.push(arguments)}e("js",new Date),e("config","G-LN6QP6VVM3")}})</script><script>"serviceWorker"in navigator&&window.addEventListener("load",function(){navigator.serviceWorker.register("/sw.js").then(function(e){console.log("SW registered: ",e)}).catch(function(e){console.log("SW registration failed: ",e)})})</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebPage","name":"Maximum Likelihood Estimation for the Normal Distribution","url":"https:\/\/yuhi-sa.github.io\/en\/posts\/20210317_bayes\/4\/","description":"A detailed walkthrough of maximum likelihood estimation (MLE) using the normal distribution, deriving the MLE for mean and variance step by step.","inLanguage":"en","isPartOf":{"@type":"WebSite","name":"tomato blog","url":"https:\/\/yuhi-sa.github.io\/"}}</script></body></html>